{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6rSku0_cX3dB"
   },
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import numpy as np\n",
    "import librosa\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction and Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWJ9phRhUDrM"
   },
   "outputs": [],
   "source": [
    "def extract_feature(file_name, **kwargs):\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma or contrast:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "        result = np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "        if contrast:\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, contrast))\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NI3q89z5YLVq"
   },
   "outputs": [],
   "source": [
    "def load_data(train_size=0.8,test_size=0.2):\n",
    "    X, y = [], []\n",
    "    try :\n",
    "        for file in glob.glob(\"C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset/Actor_*/*.wav\"):\n",
    "            # get the base name of the audio file\n",
    "            print(file)\n",
    "            basename = os.path.basename(file)\n",
    "            print(basename)\n",
    "          # get the emotion label\n",
    "            emotion = int2emotion[basename.split(\"-\")[2]]\n",
    "          # we allow only AVAILABLE_EMOTIONS we set\n",
    "            if emotion not in AVAILABLE_EMOTIONS:\n",
    "                continue\n",
    "          # extract speech features\n",
    "            features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "          # add to data\n",
    "            X.append(features)\n",
    "            l={'happy':0.0,'sad':1.0,'neutral':3.0,'angry':4.0}\n",
    "            y.append(l[emotion])\n",
    "    except :\n",
    "         pass\n",
    "    # split the data to training and testing and return it\n",
    "    return train_test_split(np.array(X), y, test_size=test_size,train_size=train_size,random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2emotion = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "AVAILABLE_EMOTIONS = {\n",
    "    \"angry\",\n",
    "    \"sad\",\n",
    "    \"neutral\",\n",
    "    \"happy\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "p7USodbIYQli",
    "outputId": "7fd11920-7a3e-405e-a828-3f7d50aa97ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-01-01-01-01-01.wav\n",
      "03-01-01-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-01-01-01-02-01.wav\n",
      "03-01-01-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-01-01-02-01-01.wav\n",
      "03-01-01-01-02-01-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0. 0. 0. ... 0. 0. 0.] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-01-01-02-02-01.wav\n",
      "03-01-01-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-01-01-01-01.wav\n",
      "03-01-02-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-01-01-02-01.wav\n",
      "03-01-02-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-01-02-01-01.wav\n",
      "03-01-02-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-01-02-02-01.wav\n",
      "03-01-02-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-02-01-01-01.wav\n",
      "03-01-02-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-02-01-02-01.wav\n",
      "03-01-02-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-02-02-01-01.wav\n",
      "03-01-02-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-02-02-02-01.wav\n",
      "03-01-02-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-01-01-01-01.wav\n",
      "03-01-03-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-01-01-02-01.wav\n",
      "03-01-03-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-01-02-01-01.wav\n",
      "03-01-03-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-01-02-02-01.wav\n",
      "03-01-03-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-02-01-01-01.wav\n",
      "03-01-03-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-02-01-02-01.wav\n",
      "03-01-03-02-01-02-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-02-02-01-01.wav\n",
      "03-01-03-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-02-02-02-01.wav\n",
      "03-01-03-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-01-01-01-01.wav\n",
      "03-01-04-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-01-01-02-01.wav\n",
      "03-01-04-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-01-02-01-01.wav\n",
      "03-01-04-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-01-02-02-01.wav\n",
      "03-01-04-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-02-01-01-01.wav\n",
      "03-01-04-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-02-01-02-01.wav\n",
      "03-01-04-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-02-02-01-01.wav\n",
      "03-01-04-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-02-02-02-01.wav\n",
      "03-01-04-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-01-01-01-01.wav\n",
      "03-01-05-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-01-01-02-01.wav\n",
      "03-01-05-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-01-02-01-01.wav\n",
      "03-01-05-01-02-01-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-0.00061035 -0.00048828 -0.00039673 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-01-02-02-01.wav\n",
      "03-01-05-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-02-01-01-01.wav\n",
      "03-01-05-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-02-01-02-01.wav\n",
      "03-01-05-02-01-02-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.00231934  0.00213623 -0.00231934 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 7.3242188e-04  1.0986328e-03 -6.7138672e-04 ...  9.1552734e-05\n",
      "  3.6621094e-04  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.00033569 0.00024414 0.00024414 ... 0.00036621 0.00033569 0.00045776] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-02-02-01-01.wav\n",
      "03-01-05-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-02-02-02-01.wav\n",
      "03-01-05-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-01-01-01-01.wav\n",
      "03-01-06-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-01-01-02-01.wav\n",
      "03-01-06-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-01-02-01-01.wav\n",
      "03-01-06-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-01-02-02-01.wav\n",
      "03-01-06-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-02-01-01-01.wav\n",
      "03-01-06-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-02-01-02-01.wav\n",
      "03-01-06-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-02-02-01-01.wav\n",
      "03-01-06-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-02-02-02-01.wav\n",
      "03-01-06-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-01-01-01-01.wav\n",
      "03-01-07-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-01-01-02-01.wav\n",
      "03-01-07-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-01-02-01-01.wav\n",
      "03-01-07-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-01-02-02-01.wav\n",
      "03-01-07-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-02-01-01-01.wav\n",
      "03-01-07-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-02-01-02-01.wav\n",
      "03-01-07-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-02-02-01-01.wav\n",
      "03-01-07-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-02-02-02-01.wav\n",
      "03-01-07-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-01-01-01-01.wav\n",
      "03-01-08-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-01-01-02-01.wav\n",
      "03-01-08-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-01-02-01-01.wav\n",
      "03-01-08-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-01-02-02-01.wav\n",
      "03-01-08-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-02-01-01-01.wav\n",
      "03-01-08-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-02-01-02-01.wav\n",
      "03-01-08-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-02-02-01-01.wav\n",
      "03-01-08-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-02-02-02-01.wav\n",
      "03-01-08-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-01-01-01-01-02.wav\n",
      "03-01-01-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-01-01-01-02-02.wav\n",
      "03-01-01-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-01-01-02-01-02.wav\n",
      "03-01-01-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-01-01-02-02-02.wav\n",
      "03-01-01-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-01-01-01-02.wav\n",
      "03-01-02-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-01-01-02-02.wav\n",
      "03-01-02-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-01-02-01-02.wav\n",
      "03-01-02-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-01-02-02-02.wav\n",
      "03-01-02-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-02-01-01-02.wav\n",
      "03-01-02-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-02-01-02-02.wav\n",
      "03-01-02-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-02-02-01-02.wav\n",
      "03-01-02-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-02-02-02-02.wav\n",
      "03-01-02-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-01-01-01-02.wav\n",
      "03-01-03-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-01-01-02-02.wav\n",
      "03-01-03-01-01-02-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-01-02-01-02.wav\n",
      "03-01-03-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-01-02-02-02.wav\n",
      "03-01-03-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-02-01-01-02.wav\n",
      "03-01-03-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-02-01-02-02.wav\n",
      "03-01-03-02-01-02-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-02-02-01-02.wav\n",
      "03-01-03-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-02-02-02-02.wav\n",
      "03-01-03-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-01-01-01-02.wav\n",
      "03-01-04-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-01-01-02-02.wav\n",
      "03-01-04-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-01-02-01-02.wav\n",
      "03-01-04-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-01-02-02-02.wav\n",
      "03-01-04-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-02-01-01-02.wav\n",
      "03-01-04-02-01-01-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-02-01-02-02.wav\n",
      "03-01-04-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-02-02-01-02.wav\n",
      "03-01-04-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-02-02-02-02.wav\n",
      "03-01-04-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-01-01-01-02.wav\n",
      "03-01-05-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-01-01-02-02.wav\n",
      "03-01-05-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-01-02-01-02.wav\n",
      "03-01-05-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-01-02-02-02.wav\n",
      "03-01-05-01-02-02-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-02-01-01-02.wav\n",
      "03-01-05-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-02-01-02-02.wav\n",
      "03-01-05-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-02-02-01-02.wav\n",
      "03-01-05-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-02-02-02-02.wav\n",
      "03-01-05-02-02-02-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 3.0517578e-05\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-01-01-01-02.wav\n",
      "03-01-06-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-01-01-02-02.wav\n",
      "03-01-06-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-01-02-01-02.wav\n",
      "03-01-06-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-01-02-02-02.wav\n",
      "03-01-06-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-02-01-01-02.wav\n",
      "03-01-06-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-02-01-02-02.wav\n",
      "03-01-06-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-02-02-01-02.wav\n",
      "03-01-06-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-02-02-02-02.wav\n",
      "03-01-06-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-01-01-01-02.wav\n",
      "03-01-07-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-01-01-02-02.wav\n",
      "03-01-07-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-01-02-01-02.wav\n",
      "03-01-07-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-01-02-02-02.wav\n",
      "03-01-07-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-02-01-01-02.wav\n",
      "03-01-07-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-02-01-02-02.wav\n",
      "03-01-07-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-02-02-01-02.wav\n",
      "03-01-07-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-02-02-02-02.wav\n",
      "03-01-07-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-01-01-01-02.wav\n",
      "03-01-08-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-01-01-02-02.wav\n",
      "03-01-08-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-01-02-01-02.wav\n",
      "03-01-08-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-01-02-02-02.wav\n",
      "03-01-08-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-02-01-01-02.wav\n",
      "03-01-08-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-02-01-02-02.wav\n",
      "03-01-08-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-02-02-01-02.wav\n",
      "03-01-08-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-02-02-02-02.wav\n",
      "03-01-08-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-01-01-01-01-03.wav\n",
      "03-01-01-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-01-01-01-02-03.wav\n",
      "03-01-01-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-01-01-02-01-03.wav\n",
      "03-01-01-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-01-01-02-02-03.wav\n",
      "03-01-01-01-02-02-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ...  6.1035156e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 3.0517578e-05 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-01-01-01-03.wav\n",
      "03-01-02-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-01-01-02-03.wav\n",
      "03-01-02-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-01-02-01-03.wav\n",
      "03-01-02-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-01-02-02-03.wav\n",
      "03-01-02-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-02-01-01-03.wav\n",
      "03-01-02-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-02-01-02-03.wav\n",
      "03-01-02-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-02-02-01-03.wav\n",
      "03-01-02-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-02-02-02-03.wav\n",
      "03-01-02-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-01-01-01-03.wav\n",
      "03-01-03-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-01-01-02-03.wav\n",
      "03-01-03-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-01-02-01-03.wav\n",
      "03-01-03-01-02-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  6.1035156e-05  9.1552734e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 5.1879883e-04 -6.1035156e-05 -4.2724609e-04 ...  0.0000000e+00\n",
      " -9.1552734e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-01-02-02-03.wav\n",
      "03-01-03-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-02-01-01-03.wav\n",
      "03-01-03-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-02-01-02-03.wav\n",
      "03-01-03-02-01-02-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 1.2207031e-04  1.5258789e-04 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-0.00027466 -0.00024414 -0.00027466 ... -0.00015259 -0.00021362\n",
      " -0.00024414] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -9.1552734e-04 -1.0986328e-03 ...  2.7465820e-04\n",
      "  3.0517578e-04  3.6621094e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -1.5258789e-04 -1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-02-02-01-03.wav\n",
      "03-01-03-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-02-02-02-03.wav\n",
      "03-01-03-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-01-01-01-03.wav\n",
      "03-01-04-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-01-01-02-03.wav\n",
      "03-01-04-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-01-02-01-03.wav\n",
      "03-01-04-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-01-02-02-03.wav\n",
      "03-01-04-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-02-01-01-03.wav\n",
      "03-01-04-02-01-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 6.1035156e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00042725 -0.00039673\n",
      " -0.00033569] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00 -3.0517578e-05 ...  2.7465820e-04\n",
      "  3.0517578e-04  2.7465820e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05  3.0517578e-05 ...  0.0000000e+00\n",
      " -3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-02-01-02-03.wav\n",
      "03-01-04-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-02-02-01-03.wav\n",
      "03-01-04-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-02-02-02-03.wav\n",
      "03-01-04-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-01-01-01-03.wav\n",
      "03-01-05-01-01-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.7138672e-04 -7.0190430e-04 -6.1035156e-04 ...  6.1035156e-05\n",
      "  6.1035156e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  3.0517578e-05 ... -3.6926270e-03\n",
      " -7.4768066e-03 -8.6975098e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00247192 0.00247192 0.00244141] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  9.1552734e-05  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-01-01-02-03.wav\n",
      "03-01-05-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-01-02-01-03.wav\n",
      "03-01-05-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-01-02-02-03.wav\n",
      "03-01-05-01-02-02-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -9.1552734e-05\n",
      " -1.8310547e-04  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -3.0517578e-05  3.0517578e-05 ... -5.8593750e-03\n",
      " -5.8898926e-03 -6.0729980e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-1.8310547e-04  1.2207031e-04  3.0517578e-04 ... -1.8310547e-04\n",
      " -6.1035156e-05 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 6.4086914e-04  2.7465820e-04 -6.1035156e-05 ... -1.7089844e-03\n",
      " -1.8615723e-03 -1.8005371e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-02-01-01-03.wav\n",
      "03-01-05-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-02-01-02-03.wav\n",
      "03-01-05-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-02-02-01-03.wav\n",
      "03-01-05-02-02-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[9.1552734e-05 2.1362305e-04 3.3569336e-04 ... 0.0000000e+00 3.0517578e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 3.0517578e-05 ... 9.4604492e-04 7.0190430e-04\n",
      " 8.8500977e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-02-02-02-03.wav\n",
      "03-01-05-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-01-01-01-03.wav\n",
      "03-01-06-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-01-01-02-03.wav\n",
      "03-01-06-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-01-02-01-03.wav\n",
      "03-01-06-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-01-02-02-03.wav\n",
      "03-01-06-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-02-01-01-03.wav\n",
      "03-01-06-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-02-01-02-03.wav\n",
      "03-01-06-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-02-02-01-03.wav\n",
      "03-01-06-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-02-02-02-03.wav\n",
      "03-01-06-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-01-01-01-03.wav\n",
      "03-01-07-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-01-01-02-03.wav\n",
      "03-01-07-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-01-02-01-03.wav\n",
      "03-01-07-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-01-02-02-03.wav\n",
      "03-01-07-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-02-01-01-03.wav\n",
      "03-01-07-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-02-01-02-03.wav\n",
      "03-01-07-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-02-02-01-03.wav\n",
      "03-01-07-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-02-02-02-03.wav\n",
      "03-01-07-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-01-01-01-03.wav\n",
      "03-01-08-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-01-01-02-03.wav\n",
      "03-01-08-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-01-02-01-03.wav\n",
      "03-01-08-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-01-02-02-03.wav\n",
      "03-01-08-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-02-01-01-03.wav\n",
      "03-01-08-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-02-01-02-03.wav\n",
      "03-01-08-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-02-02-01-03.wav\n",
      "03-01-08-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-02-02-02-03.wav\n",
      "03-01-08-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-01-01-01-01-04.wav\n",
      "03-01-01-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-01-01-01-02-04.wav\n",
      "03-01-01-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-01-01-02-01-04.wav\n",
      "03-01-01-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-01-01-02-02-04.wav\n",
      "03-01-01-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-01-01-01-04.wav\n",
      "03-01-02-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-01-01-02-04.wav\n",
      "03-01-02-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-01-02-01-04.wav\n",
      "03-01-02-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-01-02-02-04.wav\n",
      "03-01-02-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-02-01-01-04.wav\n",
      "03-01-02-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-02-01-02-04.wav\n",
      "03-01-02-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-02-02-01-04.wav\n",
      "03-01-02-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-02-02-02-04.wav\n",
      "03-01-02-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-01-01-01-04.wav\n",
      "03-01-03-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-01-01-02-04.wav\n",
      "03-01-03-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-01-02-01-04.wav\n",
      "03-01-03-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-01-02-02-04.wav\n",
      "03-01-03-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-02-01-01-04.wav\n",
      "03-01-03-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-02-01-02-04.wav\n",
      "03-01-03-02-01-02-04.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-02-02-01-04.wav\n",
      "03-01-03-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-02-02-02-04.wav\n",
      "03-01-03-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-01-01-01-04.wav\n",
      "03-01-04-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-01-01-02-04.wav\n",
      "03-01-04-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-01-02-01-04.wav\n",
      "03-01-04-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-01-02-02-04.wav\n",
      "03-01-04-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-02-01-01-04.wav\n",
      "03-01-04-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-02-01-02-04.wav\n",
      "03-01-04-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-02-02-01-04.wav\n",
      "03-01-04-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-02-02-02-04.wav\n",
      "03-01-04-02-02-02-04.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -9.1552734e-05 -9.1552734e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 9.1552734e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-01-01-01-04.wav\n",
      "03-01-05-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-01-01-02-04.wav\n",
      "03-01-05-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-01-02-01-04.wav\n",
      "03-01-05-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-01-02-02-04.wav\n",
      "03-01-05-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-02-01-01-04.wav\n",
      "03-01-05-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-02-01-02-04.wav\n",
      "03-01-05-02-01-02-04.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 6.1035156e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-02-02-01-04.wav\n",
      "03-01-05-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-02-02-02-04.wav\n",
      "03-01-05-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-01-01-01-04.wav\n",
      "03-01-06-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-01-01-02-04.wav\n",
      "03-01-06-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-01-02-01-04.wav\n",
      "03-01-06-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-01-02-02-04.wav\n",
      "03-01-06-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-02-01-01-04.wav\n",
      "03-01-06-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-02-01-02-04.wav\n",
      "03-01-06-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-02-02-01-04.wav\n",
      "03-01-06-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-02-02-02-04.wav\n",
      "03-01-06-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-01-01-01-04.wav\n",
      "03-01-07-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-01-01-02-04.wav\n",
      "03-01-07-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-01-02-01-04.wav\n",
      "03-01-07-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-01-02-02-04.wav\n",
      "03-01-07-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-02-01-01-04.wav\n",
      "03-01-07-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-02-01-02-04.wav\n",
      "03-01-07-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-02-02-01-04.wav\n",
      "03-01-07-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-02-02-02-04.wav\n",
      "03-01-07-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-01-01-01-04.wav\n",
      "03-01-08-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-01-01-02-04.wav\n",
      "03-01-08-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-01-02-01-04.wav\n",
      "03-01-08-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-01-02-02-04.wav\n",
      "03-01-08-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-02-01-01-04.wav\n",
      "03-01-08-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-02-01-02-04.wav\n",
      "03-01-08-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-02-02-01-04.wav\n",
      "03-01-08-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-02-02-02-04.wav\n",
      "03-01-08-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-01-01-01-01-05.wav\n",
      "03-01-01-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-01-01-01-02-05.wav\n",
      "03-01-01-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-01-01-02-01-05.wav\n",
      "03-01-01-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-01-01-02-02-05.wav\n",
      "03-01-01-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-01-01-01-05.wav\n",
      "03-01-02-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-01-01-02-05.wav\n",
      "03-01-02-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-01-02-01-05.wav\n",
      "03-01-02-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-01-02-02-05.wav\n",
      "03-01-02-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-02-01-01-05.wav\n",
      "03-01-02-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-02-01-02-05.wav\n",
      "03-01-02-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-02-02-01-05.wav\n",
      "03-01-02-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-02-02-02-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -9.1552734e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  3.0517578e-05  6.1035156e-05 ... -9.1552734e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-02-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-01-01-01-05.wav\n",
      "03-01-03-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-01-01-02-05.wav\n",
      "03-01-03-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-01-02-01-05.wav\n",
      "03-01-03-01-02-01-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-01-02-02-05.wav\n",
      "03-01-03-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-02-01-01-05.wav\n",
      "03-01-03-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-02-01-02-05.wav\n",
      "03-01-03-02-01-02-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 6.1035156e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-1.5258789e-04 -1.5258789e-04 -1.5258789e-04 ...  0.0000000e+00\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  6.1035156e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 3.0517578e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-02-02-01-05.wav\n",
      "03-01-03-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-02-02-02-05.wav\n",
      "03-01-03-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-01-01-01-05.wav\n",
      "03-01-04-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-01-01-02-05.wav\n",
      "03-01-04-01-01-02-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[9.1552734e-05 6.1035156e-05 6.1035156e-05 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-01-02-01-05.wav\n",
      "03-01-04-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-01-02-02-05.wav\n",
      "03-01-04-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-02-01-01-05.wav\n",
      "03-01-04-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-02-01-02-05.wav\n",
      "03-01-04-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-02-02-01-05.wav\n",
      "03-01-04-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-02-02-02-05.wav\n",
      "03-01-04-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-01-01-01-05.wav\n",
      "03-01-05-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-01-01-02-05.wav\n",
      "03-01-05-01-01-02-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.00054932 0.00057983 0.00057983 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -3.0517578e-05 ... -3.0517578e-05\n",
      " -6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-01-02-01-05.wav\n",
      "03-01-05-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-01-02-02-05.wav\n",
      "03-01-05-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-02-01-01-05.wav\n",
      "03-01-05-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-02-01-02-05.wav\n",
      "03-01-05-02-01-02-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 3.0517578e-05\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -9.1552734e-05 ...  4.2724609e-04\n",
      "  4.2724609e-04  4.2724609e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-02-02-01-05.wav\n",
      "03-01-05-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-02-02-02-05.wav\n",
      "03-01-05-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-01-01-01-05.wav\n",
      "03-01-06-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-01-01-02-05.wav\n",
      "03-01-06-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-01-02-01-05.wav\n",
      "03-01-06-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-01-02-02-05.wav\n",
      "03-01-06-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-02-01-01-05.wav\n",
      "03-01-06-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-02-01-02-05.wav\n",
      "03-01-06-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-02-02-01-05.wav\n",
      "03-01-06-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-02-02-02-05.wav\n",
      "03-01-06-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-01-01-01-05.wav\n",
      "03-01-07-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-01-01-02-05.wav\n",
      "03-01-07-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-01-02-01-05.wav\n",
      "03-01-07-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-01-02-02-05.wav\n",
      "03-01-07-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-02-01-01-05.wav\n",
      "03-01-07-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-02-01-02-05.wav\n",
      "03-01-07-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-02-02-01-05.wav\n",
      "03-01-07-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-02-02-02-05.wav\n",
      "03-01-07-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-01-01-01-05.wav\n",
      "03-01-08-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-01-01-02-05.wav\n",
      "03-01-08-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-01-02-01-05.wav\n",
      "03-01-08-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-01-02-02-05.wav\n",
      "03-01-08-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-02-01-01-05.wav\n",
      "03-01-08-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-02-01-02-05.wav\n",
      "03-01-08-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-02-02-01-05.wav\n",
      "03-01-08-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-02-02-02-05.wav\n",
      "03-01-08-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-01-01-01-01-06.wav\n",
      "03-01-01-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-01-01-01-02-06.wav\n",
      "03-01-01-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-01-01-02-01-06.wav\n",
      "03-01-01-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-01-01-02-02-06.wav\n",
      "03-01-01-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-01-01-01-06.wav\n",
      "03-01-02-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-01-01-02-06.wav\n",
      "03-01-02-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-01-02-01-06.wav\n",
      "03-01-02-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-01-02-02-06.wav\n",
      "03-01-02-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-02-01-01-06.wav\n",
      "03-01-02-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-02-01-02-06.wav\n",
      "03-01-02-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-02-02-01-06.wav\n",
      "03-01-02-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-02-02-02-06.wav\n",
      "03-01-02-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-01-01-01-06.wav\n",
      "03-01-03-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-01-01-02-06.wav\n",
      "03-01-03-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-01-02-01-06.wav\n",
      "03-01-03-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-01-02-02-06.wav\n",
      "03-01-03-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-02-01-01-06.wav\n",
      "03-01-03-02-01-01-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  6.1035156e-05  3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  3.0517578e-05\n",
      " -3.0517578e-05  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-02-01-02-06.wav\n",
      "03-01-03-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-02-02-01-06.wav\n",
      "03-01-03-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-02-02-02-06.wav\n",
      "03-01-03-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-01-01-01-06.wav\n",
      "03-01-04-01-01-01-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 3.0517578e-05 ... 6.1035156e-04 6.1035156e-04\n",
      " 5.7983398e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-01-01-02-06.wav\n",
      "03-01-04-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-01-02-01-06.wav\n",
      "03-01-04-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-01-02-02-06.wav\n",
      "03-01-04-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-02-01-01-06.wav\n",
      "03-01-04-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-02-01-02-06.wav\n",
      "03-01-04-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-02-02-01-06.wav\n",
      "03-01-04-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-02-02-02-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.00024414 0.00021362 0.00021362 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-04-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-01-01-01-06.wav\n",
      "03-01-05-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-01-01-02-06.wav\n",
      "03-01-05-01-01-02-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00015259 0.00015259 0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-01-02-01-06.wav\n",
      "03-01-05-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-01-02-02-06.wav\n",
      "03-01-05-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-02-01-01-06.wav\n",
      "03-01-05-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-02-01-02-06.wav\n",
      "03-01-05-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-02-02-01-06.wav\n",
      "03-01-05-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-02-02-02-06.wav\n",
      "03-01-05-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-01-01-01-06.wav\n",
      "03-01-06-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-01-01-02-06.wav\n",
      "03-01-06-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-01-02-01-06.wav\n",
      "03-01-06-01-02-01-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 8.2397461e-04  5.1879883e-04  3.0517578e-04 ... -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05 -3.0517578e-05 -4.8828125e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  3.0517578e-05  3.0517578e-05 ...  9.1552734e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-01-02-02-06.wav\n",
      "03-01-06-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-02-01-01-06.wav\n",
      "03-01-06-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-02-01-02-06.wav\n",
      "03-01-06-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-02-02-01-06.wav\n",
      "03-01-06-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-02-02-02-06.wav\n",
      "03-01-06-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-01-01-01-06.wav\n",
      "03-01-07-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-01-01-02-06.wav\n",
      "03-01-07-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-01-02-01-06.wav\n",
      "03-01-07-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-01-02-02-06.wav\n",
      "03-01-07-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-02-01-01-06.wav\n",
      "03-01-07-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-02-01-02-06.wav\n",
      "03-01-07-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-02-02-01-06.wav\n",
      "03-01-07-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-02-02-02-06.wav\n",
      "03-01-07-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-01-01-01-06.wav\n",
      "03-01-08-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-01-01-02-06.wav\n",
      "03-01-08-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-01-02-01-06.wav\n",
      "03-01-08-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-01-02-02-06.wav\n",
      "03-01-08-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-02-01-01-06.wav\n",
      "03-01-08-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-02-01-02-06.wav\n",
      "03-01-08-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-02-02-01-06.wav\n",
      "03-01-08-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-02-02-02-06.wav\n",
      "03-01-08-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-01-01-01-01-07.wav\n",
      "03-01-01-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-01-01-01-02-07.wav\n",
      "03-01-01-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-01-01-02-01-07.wav\n",
      "03-01-01-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-01-01-02-02-07.wav\n",
      "03-01-01-01-02-02-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-2.1362305e-04 -1.8310547e-04  6.1035156e-05 ... -1.5258789e-04\n",
      " -1.8310547e-04 -2.4414062e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -1.2207031e-04  3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  3.0517578e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-01-01-01-07.wav\n",
      "03-01-02-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-01-01-02-07.wav\n",
      "03-01-02-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-01-02-01-07.wav\n",
      "03-01-02-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-01-02-02-07.wav\n",
      "03-01-02-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-02-01-01-07.wav\n",
      "03-01-02-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-02-01-02-07.wav\n",
      "03-01-02-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-02-02-01-07.wav\n",
      "03-01-02-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-02-02-02-07.wav\n",
      "03-01-02-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-01-01-01-07.wav\n",
      "03-01-03-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-01-01-02-07.wav\n",
      "03-01-03-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-01-02-01-07.wav\n",
      "03-01-03-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-01-02-02-07.wav\n",
      "03-01-03-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-02-01-01-07.wav\n",
      "03-01-03-02-01-01-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05  0.0000000e+00  3.0517578e-05 ...  2.7465820e-04\n",
      "  2.4414062e-04  2.7465820e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  6.1035156e-05\n",
      "  9.1552734e-05  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 2.1362305e-04  7.9345703e-04 -1.2207031e-04 ...  6.1035156e-05\n",
      "  6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -3.0517578e-05 -6.1035156e-05 ... -3.3569336e-04\n",
      " -3.9672852e-04 -4.2724609e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-02-01-02-07.wav\n",
      "03-01-03-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-02-02-01-07.wav\n",
      "03-01-03-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-02-02-02-07.wav\n",
      "03-01-03-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-01-01-01-07.wav\n",
      "03-01-04-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-01-01-02-07.wav\n",
      "03-01-04-01-01-02-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  4.2724609e-04  6.4086914e-04 ...  1.2207031e-04\n",
      "  9.1552734e-05  1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-01-02-01-07.wav\n",
      "03-01-04-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-01-02-02-07.wav\n",
      "03-01-04-01-02-02-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05 -2.4414062e-04 -3.9672852e-04 ...  3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -3.0517578e-05  3.0517578e-05 ...  1.0681152e-03\n",
      "  1.0681152e-03  1.0681152e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.00042725  0.00033569  0.00033569 ... -0.00402832 -0.00390625\n",
      " -0.00390625] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-02-01-01-07.wav\n",
      "03-01-04-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-02-01-02-07.wav\n",
      "03-01-04-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-02-02-01-07.wav\n",
      "03-01-04-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-02-02-02-07.wav\n",
      "03-01-04-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-01-01-01-07.wav\n",
      "03-01-05-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-01-01-02-07.wav\n",
      "03-01-05-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-01-02-01-07.wav\n",
      "03-01-05-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-01-02-02-07.wav\n",
      "03-01-05-01-02-02-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ... -8.2397461e-04\n",
      " -8.2397461e-04 -8.2397461e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  9.1552734e-05  1.2207031e-04 ... -2.1057129e-03\n",
      " -2.1362305e-03 -2.1362305e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-02-01-01-07.wav\n",
      "03-01-05-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-02-01-02-07.wav\n",
      "03-01-05-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-02-02-01-07.wav\n",
      "03-01-05-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-02-02-02-07.wav\n",
      "03-01-05-02-02-02-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-0.00064087 -0.00057983 -0.00054932 ...  0.00231934  0.00228882\n",
      "  0.00228882] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.00012207  0.00015259  0.00012207 ... -0.00204468 -0.00201416\n",
      " -0.00204468] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -1.8310547e-04 ...  3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ... -3.3569336e-04\n",
      " -3.3569336e-04 -3.3569336e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-01-01-01-07.wav\n",
      "03-01-06-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-01-01-02-07.wav\n",
      "03-01-06-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-01-02-01-07.wav\n",
      "03-01-06-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-01-02-02-07.wav\n",
      "03-01-06-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-02-01-01-07.wav\n",
      "03-01-06-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-02-01-02-07.wav\n",
      "03-01-06-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-02-02-01-07.wav\n",
      "03-01-06-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-02-02-02-07.wav\n",
      "03-01-06-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-01-01-01-07.wav\n",
      "03-01-07-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-01-01-02-07.wav\n",
      "03-01-07-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-01-02-01-07.wav\n",
      "03-01-07-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-01-02-02-07.wav\n",
      "03-01-07-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-02-01-01-07.wav\n",
      "03-01-07-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-02-01-02-07.wav\n",
      "03-01-07-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-02-02-01-07.wav\n",
      "03-01-07-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-02-02-02-07.wav\n",
      "03-01-07-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-01-01-01-07.wav\n",
      "03-01-08-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-01-01-02-07.wav\n",
      "03-01-08-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-01-02-01-07.wav\n",
      "03-01-08-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-01-02-02-07.wav\n",
      "03-01-08-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-02-01-01-07.wav\n",
      "03-01-08-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-02-01-02-07.wav\n",
      "03-01-08-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-02-02-01-07.wav\n",
      "03-01-08-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-02-02-02-07.wav\n",
      "03-01-08-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-01-01-01-01-08.wav\n",
      "03-01-01-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-01-01-01-02-08.wav\n",
      "03-01-01-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-01-01-02-01-08.wav\n",
      "03-01-01-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-01-01-02-02-08.wav\n",
      "03-01-01-01-02-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-0.00015259 -0.00015259 -0.00015259 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[9.1552734e-05 9.1552734e-05 1.2207031e-04 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.00018311 0.00018311 0.00021362 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-01-01-01-08.wav\n",
      "03-01-02-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-01-01-02-08.wav\n",
      "03-01-02-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-01-02-01-08.wav\n",
      "03-01-02-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-01-02-02-08.wav\n",
      "03-01-02-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-02-01-01-08.wav\n",
      "03-01-02-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-02-01-02-08.wav\n",
      "03-01-02-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-02-02-01-08.wav\n",
      "03-01-02-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-02-02-02-08.wav\n",
      "03-01-02-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-01-01-01-08.wav\n",
      "03-01-03-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-01-01-02-08.wav\n",
      "03-01-03-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-01-02-01-08.wav\n",
      "03-01-03-01-02-01-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 6.1035156e-05 6.1035156e-05 ... 9.1552734e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  3.0517578e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  6.1035156e-05  3.0517578e-05 ... -1.5258789e-04\n",
      " -1.2207031e-04 -1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-01-02-02-08.wav\n",
      "03-01-03-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-02-01-01-08.wav\n",
      "03-01-03-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-02-01-02-08.wav\n",
      "03-01-03-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-02-02-01-08.wav\n",
      "03-01-03-02-02-01-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -6.1035156e-05 -6.1035156e-05 ...  6.1035156e-05\n",
      "  3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05  9.1552734e-05  9.1552734e-05 ... -3.6621094e-04\n",
      " -3.6621094e-04 -3.6621094e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -3.0517578e-05 -6.1035156e-05 ... -2.7465820e-04\n",
      " -2.1362305e-04 -1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-02-02-02-08.wav\n",
      "03-01-03-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-01-01-01-08.wav\n",
      "03-01-04-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-01-01-02-08.wav\n",
      "03-01-04-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-01-02-01-08.wav\n",
      "03-01-04-01-02-01-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[2.4414062e-04 2.4414062e-04 2.4414062e-04 ... 9.1552734e-05 9.1552734e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -9.1552734e-05\n",
      " -6.1035156e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.00012207 0.00015259 0.00015259 ... 0.00015259 0.00018311 0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-01-02-02-08.wav\n",
      "03-01-04-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-02-01-01-08.wav\n",
      "03-01-04-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-02-01-02-08.wav\n",
      "03-01-04-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-02-02-01-08.wav\n",
      "03-01-04-02-02-01-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 1.8310547e-04  2.1362305e-04  2.1362305e-04 ... -1.2207031e-04\n",
      "  0.0000000e+00 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00088501 0.00076294 0.00076294] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 3.0517578e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00231934 0.00238037 0.00234985] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-02-02-02-08.wav\n",
      "03-01-04-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-01-01-01-08.wav\n",
      "03-01-05-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-01-01-02-08.wav\n",
      "03-01-05-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-01-02-01-08.wav\n",
      "03-01-05-01-02-01-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ... -8.5449219e-04\n",
      " -6.4086914e-04  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05  0.0000000e+00 ... -2.4414062e-04\n",
      " -2.1667480e-03 -2.4414062e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -9.1552734e-05 -9.1552734e-05 ...  0.0000000e+00\n",
      "  6.1035156e-05  1.8310547e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-0.00018311 -0.00018311 -0.00018311 ...  0.00027466  0.00027466\n",
      "  0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-01-02-02-08.wav\n",
      "03-01-05-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-02-01-01-08.wav\n",
      "03-01-05-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-02-01-02-08.wav\n",
      "03-01-05-02-01-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.00018311  0.00015259  0.00018311 ... -0.00021362 -0.00018311\n",
      " -0.00015259] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.00012207 0.00012207 0.00012207 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[1.8310547e-04 1.8310547e-04 1.8310547e-04 ... 3.0517578e-05 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-02-02-01-08.wav\n",
      "03-01-05-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-02-02-02-08.wav\n",
      "03-01-05-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-01-01-01-08.wav\n",
      "03-01-06-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-01-01-02-08.wav\n",
      "03-01-06-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-01-02-01-08.wav\n",
      "03-01-06-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-01-02-02-08.wav\n",
      "03-01-06-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-02-01-01-08.wav\n",
      "03-01-06-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-02-01-02-08.wav\n",
      "03-01-06-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-02-02-01-08.wav\n",
      "03-01-06-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-02-02-02-08.wav\n",
      "03-01-06-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-01-01-01-08.wav\n",
      "03-01-07-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-01-01-02-08.wav\n",
      "03-01-07-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-01-02-01-08.wav\n",
      "03-01-07-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-01-02-02-08.wav\n",
      "03-01-07-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-02-01-01-08.wav\n",
      "03-01-07-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-02-01-02-08.wav\n",
      "03-01-07-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-02-02-01-08.wav\n",
      "03-01-07-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-02-02-02-08.wav\n",
      "03-01-07-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-01-01-01-08.wav\n",
      "03-01-08-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-01-01-02-08.wav\n",
      "03-01-08-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-01-02-01-08.wav\n",
      "03-01-08-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-01-02-02-08.wav\n",
      "03-01-08-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-02-01-01-08.wav\n",
      "03-01-08-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-02-01-02-08.wav\n",
      "03-01-08-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-02-02-01-08.wav\n",
      "03-01-08-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-02-02-02-08.wav\n",
      "03-01-08-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-01-01-01-01-09.wav\n",
      "03-01-01-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-01-01-01-02-09.wav\n",
      "03-01-01-01-01-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 8.5449219e-04  8.5449219e-04  8.8500977e-04 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-01-01-02-01-09.wav\n",
      "03-01-01-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-01-01-02-02-09.wav\n",
      "03-01-01-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-01-01-01-09.wav\n",
      "03-01-02-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-01-01-02-09.wav\n",
      "03-01-02-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-01-02-01-09.wav\n",
      "03-01-02-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-01-02-02-09.wav\n",
      "03-01-02-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-02-01-01-09.wav\n",
      "03-01-02-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-02-01-02-09.wav\n",
      "03-01-02-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-02-02-01-09.wav\n",
      "03-01-02-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-02-02-02-09.wav\n",
      "03-01-02-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-01-01-01-09.wav\n",
      "03-01-03-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-01-01-02-09.wav\n",
      "03-01-03-01-01-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05  1.2207031e-04  1.2207031e-04 ... -3.0517578e-05\n",
      " -6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0007019  0.00067139 0.00067139 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-01-02-01-09.wav\n",
      "03-01-03-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-01-02-02-09.wav\n",
      "03-01-03-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-02-01-01-09.wav\n",
      "03-01-03-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-02-01-02-09.wav\n",
      "03-01-03-02-01-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -3.0517578e-05 ... -1.2207031e-04\n",
      " -1.2207031e-04 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -9.1552734e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05  3.0517578e-05  3.0517578e-05 ...  6.1035156e-05\n",
      " -3.0517578e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-02-02-01-09.wav\n",
      "03-01-03-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-02-02-02-09.wav\n",
      "03-01-03-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-01-01-01-09.wav\n",
      "03-01-04-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-01-01-02-09.wav\n",
      "03-01-04-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-01-02-01-09.wav\n",
      "03-01-04-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-01-02-02-09.wav\n",
      "03-01-04-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-02-01-01-09.wav\n",
      "03-01-04-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-02-01-02-09.wav\n",
      "03-01-04-02-01-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-02-02-01-09.wav\n",
      "03-01-04-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-02-02-02-09.wav\n",
      "03-01-04-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-01-01-01-09.wav\n",
      "03-01-05-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-01-01-02-09.wav\n",
      "03-01-05-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-01-02-01-09.wav\n",
      "03-01-05-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-01-02-02-09.wav\n",
      "03-01-05-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-02-01-01-09.wav\n",
      "03-01-05-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-02-01-02-09.wav\n",
      "03-01-05-02-01-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00012207 -0.00012207\n",
      " -0.00015259] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05  0.0000000e+00 ... -2.7465820e-04\n",
      " -3.0517578e-04 -2.7465820e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -1.5258789e-04\n",
      " -1.2207031e-04 -2.1362305e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[9.1552734e-05 1.2207031e-04 1.8310547e-04 ... 1.5258789e-04 1.8310547e-04\n",
      " 1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-02-02-01-09.wav\n",
      "03-01-05-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-02-02-02-09.wav\n",
      "03-01-05-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-01-01-01-09.wav\n",
      "03-01-06-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-01-01-02-09.wav\n",
      "03-01-06-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-01-02-01-09.wav\n",
      "03-01-06-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-01-02-02-09.wav\n",
      "03-01-06-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-02-01-01-09.wav\n",
      "03-01-06-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-02-01-02-09.wav\n",
      "03-01-06-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-02-02-01-09.wav\n",
      "03-01-06-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-02-02-02-09.wav\n",
      "03-01-06-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-01-01-01-09.wav\n",
      "03-01-07-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-01-01-02-09.wav\n",
      "03-01-07-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-01-02-01-09.wav\n",
      "03-01-07-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-01-02-02-09.wav\n",
      "03-01-07-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-02-01-01-09.wav\n",
      "03-01-07-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-02-01-02-09.wav\n",
      "03-01-07-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-02-02-01-09.wav\n",
      "03-01-07-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-02-02-02-09.wav\n",
      "03-01-07-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-01-01-01-09.wav\n",
      "03-01-08-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-01-01-02-09.wav\n",
      "03-01-08-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-01-02-01-09.wav\n",
      "03-01-08-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-01-02-02-09.wav\n",
      "03-01-08-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-02-01-01-09.wav\n",
      "03-01-08-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-02-01-02-09.wav\n",
      "03-01-08-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-02-02-01-09.wav\n",
      "03-01-08-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-02-02-02-09.wav\n",
      "03-01-08-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-01-01-01-01-10.wav\n",
      "03-01-01-01-01-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.00027466  0.00048828  0.0005188  ... -0.00036621 -0.00042725\n",
      " -0.00033569] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 3.0517578e-05 6.1035156e-05 ... 0.0000000e+00 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  2.7465820e-04 ...  6.1035156e-05\n",
      "  9.1552734e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-01-01-01-02-10.wav\n",
      "03-01-01-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-01-01-02-01-10.wav\n",
      "03-01-01-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-01-01-02-02-10.wav\n",
      "03-01-01-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-01-01-01-10.wav\n",
      "03-01-02-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-01-01-02-10.wav\n",
      "03-01-02-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-01-02-01-10.wav\n",
      "03-01-02-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-01-02-02-10.wav\n",
      "03-01-02-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-02-01-01-10.wav\n",
      "03-01-02-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-02-01-02-10.wav\n",
      "03-01-02-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-02-02-01-10.wav\n",
      "03-01-02-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-02-02-02-10.wav\n",
      "03-01-02-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-01-01-01-10.wav\n",
      "03-01-03-01-01-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05  9.1552734e-05  9.1552734e-05 ... -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00  3.0517578e-05 ...  0.0000000e+00\n",
      " -9.1552734e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-01-01-02-10.wav\n",
      "03-01-03-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-01-02-01-10.wav\n",
      "03-01-03-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-01-02-02-10.wav\n",
      "03-01-03-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-02-01-01-10.wav\n",
      "03-01-03-02-01-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  3.0517578e-05 ...  3.9672852e-04\n",
      "  4.5776367e-04 -2.7465820e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-2.7465820e-04  1.8310547e-04 -6.1035156e-05 ...  9.1552734e-05\n",
      "  1.2207031e-04  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -3.0517578e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ...  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-02-01-02-10.wav\n",
      "03-01-03-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-02-02-01-10.wav\n",
      "03-01-03-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-02-02-02-10.wav\n",
      "03-01-03-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-01-01-01-10.wav\n",
      "03-01-04-01-01-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05  9.1552734e-05  9.1552734e-05 ... -1.2207031e-04\n",
      " -9.1552734e-05 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 1.4648438e-03  6.1035156e-04  2.1667480e-03 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-01-01-02-10.wav\n",
      "03-01-04-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-01-02-01-10.wav\n",
      "03-01-04-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-01-02-02-10.wav\n",
      "03-01-04-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-02-01-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -1.2207031e-04 -9.1552734e-05 ...  0.0000000e+00\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05 -6.1035156e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 6.1035156e-05 6.1035156e-05 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-04-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-02-01-02-10.wav\n",
      "03-01-04-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-02-02-01-10.wav\n",
      "03-01-04-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-02-02-02-10.wav\n",
      "03-01-04-02-02-02-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.9672852e-04  1.8310547e-04 -2.7465820e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05 -3.0517578e-05 -2.1362305e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-1.5258789e-04  6.1035156e-05  1.5258789e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-01-01-01-10.wav\n",
      "03-01-05-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-01-01-02-10.wav\n",
      "03-01-05-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-01-02-01-10.wav\n",
      "03-01-05-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-01-02-02-10.wav\n",
      "03-01-05-01-02-02-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 6.4086914e-04  2.7465820e-04 -4.5776367e-04 ...  1.2207031e-04\n",
      "  9.1552734e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 1.5258789e-04 1.2207031e-04 ... 3.0517578e-05 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[1.5258789e-04 1.5258789e-04 1.8310547e-04 ... 3.0517578e-05 3.0517578e-05\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-02-01-01-10.wav\n",
      "03-01-05-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-02-01-02-10.wav\n",
      "03-01-05-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-02-02-01-10.wav\n",
      "03-01-05-02-02-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05  3.0517578e-05  6.1035156e-05 ... -3.0517578e-05\n",
      "  6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-02-02-02-10.wav\n",
      "03-01-05-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-01-01-01-10.wav\n",
      "03-01-06-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-01-01-02-10.wav\n",
      "03-01-06-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-01-02-01-10.wav\n",
      "03-01-06-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-01-02-02-10.wav\n",
      "03-01-06-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-02-01-01-10.wav\n",
      "03-01-06-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-02-01-02-10.wav\n",
      "03-01-06-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-02-02-01-10.wav\n",
      "03-01-06-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-02-02-02-10.wav\n",
      "03-01-06-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-01-01-01-10.wav\n",
      "03-01-07-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-01-01-02-10.wav\n",
      "03-01-07-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-01-02-01-10.wav\n",
      "03-01-07-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-01-02-02-10.wav\n",
      "03-01-07-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-02-01-01-10.wav\n",
      "03-01-07-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-02-01-02-10.wav\n",
      "03-01-07-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-02-02-01-10.wav\n",
      "03-01-07-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-02-02-02-10.wav\n",
      "03-01-07-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-01-01-01-10.wav\n",
      "03-01-08-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-01-01-02-10.wav\n",
      "03-01-08-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-01-02-01-10.wav\n",
      "03-01-08-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-01-02-02-10.wav\n",
      "03-01-08-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-02-01-01-10.wav\n",
      "03-01-08-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-02-01-02-10.wav\n",
      "03-01-08-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-02-02-01-10.wav\n",
      "03-01-08-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-02-02-02-10.wav\n",
      "03-01-08-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-01-01-01-01-11.wav\n",
      "03-01-01-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-01-01-01-02-11.wav\n",
      "03-01-01-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-01-01-02-01-11.wav\n",
      "03-01-01-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-01-01-02-02-11.wav\n",
      "03-01-01-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-01-01-01-11.wav\n",
      "03-01-02-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-01-01-02-11.wav\n",
      "03-01-02-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-01-02-01-11.wav\n",
      "03-01-02-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-01-02-02-11.wav\n",
      "03-01-02-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-02-01-01-11.wav\n",
      "03-01-02-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-02-01-02-11.wav\n",
      "03-01-02-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-02-02-01-11.wav\n",
      "03-01-02-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-02-02-02-11.wav\n",
      "03-01-02-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-01-01-01-11.wav\n",
      "03-01-03-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-01-01-02-11.wav\n",
      "03-01-03-01-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  4.5776367e-04\n",
      "  4.5776367e-04  4.5776367e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -9.1552734e-05 -6.1035156e-05 ... -3.0517578e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05  3.0517578e-05 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 3.0517578e-05 ... 6.1035156e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-01-02-01-11.wav\n",
      "03-01-03-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-01-02-02-11.wav\n",
      "03-01-03-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-02-01-01-11.wav\n",
      "03-01-03-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-02-01-02-11.wav\n",
      "03-01-03-02-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.1552734e-05 6.1035156e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.1552734e-05 9.1552734e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  2.1362305e-04  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-02-02-01-11.wav\n",
      "03-01-03-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-02-02-02-11.wav\n",
      "03-01-03-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-01-01-01-11.wav\n",
      "03-01-04-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-01-01-02-11.wav\n",
      "03-01-04-01-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[1.2207031e-04 9.1552734e-05 9.1552734e-05 ... 1.8310547e-04 1.8310547e-04\n",
      " 1.8310547e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 1.5258789e-04  1.2207031e-04  1.2207031e-04 ... -6.1035156e-05\n",
      " -6.1035156e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-01-02-01-11.wav\n",
      "03-01-04-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-01-02-02-11.wav\n",
      "03-01-04-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-02-01-01-11.wav\n",
      "03-01-04-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-02-01-02-11.wav\n",
      "03-01-04-02-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -6.1035156e-05 ...  3.0517578e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05  3.0517578e-05 ... -9.1552734e-05\n",
      " -9.1552734e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-02-02-01-11.wav\n",
      "03-01-04-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-02-02-02-11.wav\n",
      "03-01-04-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-01-01-01-11.wav\n",
      "03-01-05-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-01-01-02-11.wav\n",
      "03-01-05-01-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 9.1552734e-05 9.1552734e-05 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -1.5258789e-04 -1.5258789e-04 ...  6.1035156e-05\n",
      "  6.1035156e-05  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-01-02-01-11.wav\n",
      "03-01-05-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-01-02-02-11.wav\n",
      "03-01-05-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-02-01-01-11.wav\n",
      "03-01-05-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-02-01-02-11.wav\n",
      "03-01-05-02-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -6.1035156e-05 -6.1035156e-05 ...  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00027466 -0.00027466\n",
      " -0.00027466] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -9.1552734e-05 -6.1035156e-05 ... -1.2207031e-04\n",
      " -9.1552734e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-02-02-01-11.wav\n",
      "03-01-05-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-02-02-02-11.wav\n",
      "03-01-05-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-01-01-01-11.wav\n",
      "03-01-06-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-01-01-02-11.wav\n",
      "03-01-06-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-01-02-01-11.wav\n",
      "03-01-06-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-01-02-02-11.wav\n",
      "03-01-06-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-02-01-01-11.wav\n",
      "03-01-06-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-02-01-02-11.wav\n",
      "03-01-06-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-02-02-01-11.wav\n",
      "03-01-06-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-02-02-02-11.wav\n",
      "03-01-06-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-01-01-01-11.wav\n",
      "03-01-07-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-01-01-02-11.wav\n",
      "03-01-07-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-01-02-01-11.wav\n",
      "03-01-07-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-01-02-02-11.wav\n",
      "03-01-07-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-02-01-01-11.wav\n",
      "03-01-07-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-02-01-02-11.wav\n",
      "03-01-07-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-02-02-01-11.wav\n",
      "03-01-07-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-02-02-02-11.wav\n",
      "03-01-07-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-01-01-01-11.wav\n",
      "03-01-08-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-01-01-02-11.wav\n",
      "03-01-08-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-01-02-01-11.wav\n",
      "03-01-08-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-01-02-02-11.wav\n",
      "03-01-08-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-02-01-01-11.wav\n",
      "03-01-08-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-02-01-02-11.wav\n",
      "03-01-08-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-02-02-01-11.wav\n",
      "03-01-08-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-02-02-02-11.wav\n",
      "03-01-08-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-01-01-01-01-12.wav\n",
      "03-01-01-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-01-01-01-02-12.wav\n",
      "03-01-01-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-01-01-02-01-12.wav\n",
      "03-01-01-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-01-01-02-02-12.wav\n",
      "03-01-01-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-01-01-01-12.wav\n",
      "03-01-02-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-01-01-02-12.wav\n",
      "03-01-02-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-01-02-01-12.wav\n",
      "03-01-02-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-01-02-02-12.wav\n",
      "03-01-02-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-02-01-01-12.wav\n",
      "03-01-02-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-02-01-02-12.wav\n",
      "03-01-02-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-02-02-01-12.wav\n",
      "03-01-02-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-02-02-02-12.wav\n",
      "03-01-02-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-01-01-01-12.wav\n",
      "03-01-03-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-01-01-02-12.wav\n",
      "03-01-03-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-01-02-01-12.wav\n",
      "03-01-03-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-01-02-02-12.wav\n",
      "03-01-03-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-02-01-01-12.wav\n",
      "03-01-03-02-01-01-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00021362 -0.00024414\n",
      " -0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-02-01-02-12.wav\n",
      "03-01-03-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-02-02-01-12.wav\n",
      "03-01-03-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-02-02-02-12.wav\n",
      "03-01-03-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-01-01-01-12.wav\n",
      "03-01-04-01-01-01-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -3.0212402e-03\n",
      " -3.0212402e-03 -3.0212402e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[1.5258789e-04 1.5258789e-04 9.1552734e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-01-01-02-12.wav\n",
      "03-01-04-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-01-02-01-12.wav\n",
      "03-01-04-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-01-02-02-12.wav\n",
      "03-01-04-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-02-01-01-12.wav\n",
      "03-01-04-02-01-01-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.00033569 0.00033569 0.00033569 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.0015564  -0.0015564\n",
      " -0.00158691] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-02-01-02-12.wav\n",
      "03-01-04-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-02-02-01-12.wav\n",
      "03-01-04-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-02-02-02-12.wav\n",
      "03-01-04-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-01-01-01-12.wav\n",
      "03-01-05-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-01-01-02-12.wav\n",
      "03-01-05-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-01-02-01-12.wav\n",
      "03-01-05-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-01-02-02-12.wav\n",
      "03-01-05-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-02-01-01-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00152588 -0.00149536\n",
      " -0.00149536] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00283813 0.0027771  0.0027771 ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-05-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-02-01-02-12.wav\n",
      "03-01-05-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-02-02-01-12.wav\n",
      "03-01-05-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-02-02-02-12.wav\n",
      "03-01-05-02-02-02-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00021362 -0.00027466\n",
      " -0.00024414] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ... -6.1035156e-05\n",
      " -3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-01-01-01-12.wav\n",
      "03-01-06-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-01-01-02-12.wav\n",
      "03-01-06-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-01-02-01-12.wav\n",
      "03-01-06-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-01-02-02-12.wav\n",
      "03-01-06-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-02-01-01-12.wav\n",
      "03-01-06-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-02-01-02-12.wav\n",
      "03-01-06-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-02-02-01-12.wav\n",
      "03-01-06-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-02-02-02-12.wav\n",
      "03-01-06-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-01-01-01-12.wav\n",
      "03-01-07-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-01-01-02-12.wav\n",
      "03-01-07-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-01-02-01-12.wav\n",
      "03-01-07-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-01-02-02-12.wav\n",
      "03-01-07-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-02-01-01-12.wav\n",
      "03-01-07-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-02-01-02-12.wav\n",
      "03-01-07-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-02-02-01-12.wav\n",
      "03-01-07-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-02-02-02-12.wav\n",
      "03-01-07-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-01-01-01-12.wav\n",
      "03-01-08-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-01-01-02-12.wav\n",
      "03-01-08-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-01-02-01-12.wav\n",
      "03-01-08-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-01-02-02-12.wav\n",
      "03-01-08-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-02-01-01-12.wav\n",
      "03-01-08-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-02-01-02-12.wav\n",
      "03-01-08-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-02-02-01-12.wav\n",
      "03-01-08-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-02-02-02-12.wav\n",
      "03-01-08-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-01-01-01-01-13.wav\n",
      "03-01-01-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-01-01-01-02-13.wav\n",
      "03-01-01-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-01-01-02-01-13.wav\n",
      "03-01-01-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-01-01-02-02-13.wav\n",
      "03-01-01-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-01-01-01-13.wav\n",
      "03-01-02-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-01-01-02-13.wav\n",
      "03-01-02-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-01-02-01-13.wav\n",
      "03-01-02-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-01-02-02-13.wav\n",
      "03-01-02-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-02-01-01-13.wav\n",
      "03-01-02-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-02-01-02-13.wav\n",
      "03-01-02-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-02-02-01-13.wav\n",
      "03-01-02-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-02-02-02-13.wav\n",
      "03-01-02-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-01-01-01-13.wav\n",
      "03-01-03-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-01-01-02-13.wav\n",
      "03-01-03-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-01-02-01-13.wav\n",
      "03-01-03-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-01-02-02-13.wav\n",
      "03-01-03-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-02-01-01-13.wav\n",
      "03-01-03-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-02-01-02-13.wav\n",
      "03-01-03-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-02-02-01-13.wav\n",
      "03-01-03-02-02-01-13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  3.0517578e-05  3.0517578e-05 ... -6.1035156e-05\n",
      " -9.1552734e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-02-02-02-13.wav\n",
      "03-01-03-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-01-01-01-13.wav\n",
      "03-01-04-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-01-01-02-13.wav\n",
      "03-01-04-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-01-02-01-13.wav\n",
      "03-01-04-01-02-01-13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 6.1035156e-05 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-01-02-02-13.wav\n",
      "03-01-04-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-02-01-01-13.wav\n",
      "03-01-04-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-02-01-02-13.wav\n",
      "03-01-04-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-02-02-01-13.wav\n",
      "03-01-04-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-02-02-02-13.wav\n",
      "03-01-04-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-01-01-01-13.wav\n",
      "03-01-05-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-01-01-02-13.wav\n",
      "03-01-05-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-01-02-01-13.wav\n",
      "03-01-05-01-02-01-13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-01-02-02-13.wav\n",
      "03-01-05-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-02-01-01-13.wav\n",
      "03-01-05-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-02-01-02-13.wav\n",
      "03-01-05-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-02-02-01-13.wav\n",
      "03-01-05-02-02-01-13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -7.9345703e-04\n",
      " -8.2397461e-04 -8.2397461e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00012207 0.00012207 0.00015259] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-02-02-02-13.wav\n",
      "03-01-05-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-01-01-01-13.wav\n",
      "03-01-06-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-01-01-02-13.wav\n",
      "03-01-06-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-01-02-01-13.wav\n",
      "03-01-06-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-01-02-02-13.wav\n",
      "03-01-06-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-02-01-01-13.wav\n",
      "03-01-06-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-02-01-02-13.wav\n",
      "03-01-06-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-02-02-01-13.wav\n",
      "03-01-06-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-02-02-02-13.wav\n",
      "03-01-06-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-01-01-01-13.wav\n",
      "03-01-07-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-01-01-02-13.wav\n",
      "03-01-07-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-01-02-01-13.wav\n",
      "03-01-07-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-01-02-02-13.wav\n",
      "03-01-07-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-02-01-01-13.wav\n",
      "03-01-07-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-02-01-02-13.wav\n",
      "03-01-07-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-02-02-01-13.wav\n",
      "03-01-07-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-02-02-02-13.wav\n",
      "03-01-07-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-01-01-01-13.wav\n",
      "03-01-08-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-01-01-02-13.wav\n",
      "03-01-08-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-01-02-01-13.wav\n",
      "03-01-08-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-01-02-02-13.wav\n",
      "03-01-08-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-02-01-01-13.wav\n",
      "03-01-08-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-02-01-02-13.wav\n",
      "03-01-08-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-02-02-01-13.wav\n",
      "03-01-08-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-02-02-02-13.wav\n",
      "03-01-08-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-01-01-01-01-14.wav\n",
      "03-01-01-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-01-01-01-02-14.wav\n",
      "03-01-01-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-01-01-02-01-14.wav\n",
      "03-01-01-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-01-01-02-02-14.wav\n",
      "03-01-01-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-01-01-01-14.wav\n",
      "03-01-02-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-01-01-02-14.wav\n",
      "03-01-02-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-01-02-01-14.wav\n",
      "03-01-02-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-01-02-02-14.wav\n",
      "03-01-02-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-02-01-01-14.wav\n",
      "03-01-02-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-02-01-02-14.wav\n",
      "03-01-02-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-02-02-01-14.wav\n",
      "03-01-02-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-02-02-02-14.wav\n",
      "03-01-02-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-01-01-01-14.wav\n",
      "03-01-03-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-01-01-02-14.wav\n",
      "03-01-03-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-01-02-01-14.wav\n",
      "03-01-03-01-02-01-14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 3.0517578e-05 ... 0.0000000e+00 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-01-02-02-14.wav\n",
      "03-01-03-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-02-01-01-14.wav\n",
      "03-01-03-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-02-01-02-14.wav\n",
      "03-01-03-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-02-02-01-14.wav"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "03-01-03-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-02-02-02-14.wav\n",
      "03-01-03-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-01-01-01-14.wav\n",
      "03-01-04-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-01-01-02-14.wav\n",
      "03-01-04-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-01-02-01-14.wav\n",
      "03-01-04-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-01-02-02-14.wav\n",
      "03-01-04-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-02-01-01-14.wav\n",
      "03-01-04-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-02-01-02-14.wav\n",
      "03-01-04-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-02-02-01-14.wav\n",
      "03-01-04-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-02-02-02-14.wav\n",
      "03-01-04-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-01-01-01-14.wav\n",
      "03-01-05-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-01-01-02-14.wav\n",
      "03-01-05-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-01-02-01-14.wav\n",
      "03-01-05-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-01-02-02-14.wav\n",
      "03-01-05-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-02-01-01-14.wav\n",
      "03-01-05-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-02-01-02-14.wav\n",
      "03-01-05-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-02-02-01-14.wav\n",
      "03-01-05-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-02-02-02-14.wav\n",
      "03-01-05-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-01-01-01-14.wav\n",
      "03-01-06-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-01-01-02-14.wav\n",
      "03-01-06-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-01-02-01-14.wav\n",
      "03-01-06-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-01-02-02-14.wav\n",
      "03-01-06-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-02-01-01-14.wav\n",
      "03-01-06-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-02-01-02-14.wav\n",
      "03-01-06-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-02-02-01-14.wav\n",
      "03-01-06-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-02-02-02-14.wav\n",
      "03-01-06-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-01-01-01-14.wav\n",
      "03-01-07-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-01-01-02-14.wav\n",
      "03-01-07-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-01-02-01-14.wav\n",
      "03-01-07-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-01-02-02-14.wav\n",
      "03-01-07-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-02-01-01-14.wav\n",
      "03-01-07-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-02-01-02-14.wav\n",
      "03-01-07-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-02-02-01-14.wav\n",
      "03-01-07-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-02-02-02-14.wav\n",
      "03-01-07-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-01-01-01-14.wav\n",
      "03-01-08-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-01-01-02-14.wav\n",
      "03-01-08-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-01-02-01-14.wav\n",
      "03-01-08-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-01-02-02-14.wav\n",
      "03-01-08-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-02-01-01-14.wav\n",
      "03-01-08-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-02-01-02-14.wav\n",
      "03-01-08-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-02-02-01-14.wav\n",
      "03-01-08-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-02-02-02-14.wav\n",
      "03-01-08-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-01-01-01-01-15.wav\n",
      "03-01-01-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-01-01-01-02-15.wav\n",
      "03-01-01-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-01-01-02-01-15.wav\n",
      "03-01-01-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-01-01-02-02-15.wav\n",
      "03-01-01-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-01-01-01-15.wav\n",
      "03-01-02-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-01-01-02-15.wav\n",
      "03-01-02-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-01-02-01-15.wav\n",
      "03-01-02-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-01-02-02-15.wav\n",
      "03-01-02-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-02-01-01-15.wav\n",
      "03-01-02-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-02-01-02-15.wav\n",
      "03-01-02-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-02-02-01-15.wav\n",
      "03-01-02-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-02-02-02-15.wav\n",
      "03-01-02-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-01-01-01-15.wav\n",
      "03-01-03-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-01-01-02-15.wav\n",
      "03-01-03-01-01-02-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 3.0517578e-05 ... 1.2207031e-04 1.2207031e-04\n",
      " 1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00210571 -0.00216675\n",
      " -0.0020752 ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-01-02-01-15.wav\n",
      "03-01-03-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-01-02-02-15.wav\n",
      "03-01-03-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-02-01-01-15.wav\n",
      "03-01-03-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-02-01-02-15.wav\n",
      "03-01-03-02-01-02-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -6.1035156e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.1552734e-05 1.2207031e-04\n",
      " 1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 0.0000000e+00 3.0517578e-05 ... 1.5258789e-04 1.5258789e-04\n",
      " 1.8310547e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-02-02-01-15.wav\n",
      "03-01-03-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-02-02-02-15.wav\n",
      "03-01-03-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-01-01-01-15.wav\n",
      "03-01-04-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-01-01-02-15.wav\n",
      "03-01-04-01-01-02-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-1.5258789e-04 -1.5258789e-04 -1.5258789e-04 ...  9.1552734e-05\n",
      "  9.1552734e-05  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00 -3.0517578e-05 ...  1.5258789e-04\n",
      "  1.5258789e-04  1.8310547e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-01-02-01-15.wav\n",
      "03-01-04-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-01-02-02-15.wav\n",
      "03-01-04-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-02-01-01-15.wav\n",
      "03-01-04-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-02-01-02-15.wav\n",
      "03-01-04-02-01-02-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00042725 0.00042725 0.00042725] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -1.2207031e-04 -1.2207031e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00 -3.0517578e-05 ...  1.3732910e-03\n",
      "  1.4038086e-03  1.4343262e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05  3.0517578e-05  1.2207031e-04 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-02-02-01-15.wav\n",
      "03-01-04-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-02-02-02-15.wav\n",
      "03-01-04-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-01-01-01-15.wav\n",
      "03-01-05-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-01-01-02-15.wav\n",
      "03-01-05-01-01-02-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -1.2207031e-04\n",
      " -1.5258789e-04 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00 -3.0517578e-05 ...  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-01-02-01-15.wav\n",
      "03-01-05-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-01-02-02-15.wav\n",
      "03-01-05-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-02-01-01-15.wav\n",
      "03-01-05-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-02-01-02-15.wav\n",
      "03-01-05-02-01-02-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  0.0000000e+00 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00012207 -0.00012207\n",
      " -0.00012207] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  1.2207031e-04\n",
      "  1.5258789e-04  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-02-02-01-15.wav\n",
      "03-01-05-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-02-02-02-15.wav\n",
      "03-01-05-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-01-01-01-15.wav\n",
      "03-01-06-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-01-01-02-15.wav\n",
      "03-01-06-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-01-02-01-15.wav\n",
      "03-01-06-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-01-02-02-15.wav\n",
      "03-01-06-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-02-01-01-15.wav\n",
      "03-01-06-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-02-01-02-15.wav\n",
      "03-01-06-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-02-02-01-15.wav\n",
      "03-01-06-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-02-02-02-15.wav\n",
      "03-01-06-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-01-01-01-15.wav\n",
      "03-01-07-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-01-01-02-15.wav\n",
      "03-01-07-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-01-02-01-15.wav\n",
      "03-01-07-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-01-02-02-15.wav\n",
      "03-01-07-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-02-01-01-15.wav\n",
      "03-01-07-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-02-01-02-15.wav\n",
      "03-01-07-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-02-02-01-15.wav\n",
      "03-01-07-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-02-02-02-15.wav\n",
      "03-01-07-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-01-01-01-15.wav\n",
      "03-01-08-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-01-01-02-15.wav\n",
      "03-01-08-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-01-02-01-15.wav\n",
      "03-01-08-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-01-02-02-15.wav\n",
      "03-01-08-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-02-01-01-15.wav\n",
      "03-01-08-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-02-01-02-15.wav\n",
      "03-01-08-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-02-02-01-15.wav\n",
      "03-01-08-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-02-02-02-15.wav\n",
      "03-01-08-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-01-01-01-01-16.wav\n",
      "03-01-01-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-01-01-01-02-16.wav\n",
      "03-01-01-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-01-01-02-01-16.wav\n",
      "03-01-01-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-01-01-02-02-16.wav\n",
      "03-01-01-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-01-01-01-16.wav\n",
      "03-01-02-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-01-01-02-16.wav\n",
      "03-01-02-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-01-02-01-16.wav\n",
      "03-01-02-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-01-02-02-16.wav\n",
      "03-01-02-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-02-01-01-16.wav\n",
      "03-01-02-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-02-01-02-16.wav\n",
      "03-01-02-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-02-02-01-16.wav\n",
      "03-01-02-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-02-02-02-16.wav\n",
      "03-01-02-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-01-01-01-16.wav\n",
      "03-01-03-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-01-01-02-16.wav\n",
      "03-01-03-01-01-02-16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 6.1035156e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-01-02-01-16.wav\n",
      "03-01-03-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-01-02-02-16.wav\n",
      "03-01-03-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-02-01-01-16.wav\n",
      "03-01-03-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-02-01-02-16.wav\n",
      "03-01-03-02-01-02-16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      " -6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-02-02-01-16.wav\n",
      "03-01-03-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-02-02-02-16.wav\n",
      "03-01-03-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-01-01-01-16.wav\n",
      "03-01-04-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-01-01-02-16.wav\n",
      "03-01-04-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-01-02-01-16.wav\n",
      "03-01-04-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-01-02-02-16.wav\n",
      "03-01-04-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-02-01-01-16.wav\n",
      "03-01-04-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-02-01-02-16.wav\n",
      "03-01-04-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-02-02-01-16.wav\n",
      "03-01-04-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-02-02-02-16.wav\n",
      "03-01-04-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-01-01-01-16.wav\n",
      "03-01-05-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-01-01-02-16.wav\n",
      "03-01-05-01-01-02-16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -6.1035156e-05 -1.5258789e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-01-02-01-16.wav\n",
      "03-01-05-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-01-02-02-16.wav\n",
      "03-01-05-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-02-01-01-16.wav\n",
      "03-01-05-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-02-01-02-16.wav\n",
      "03-01-05-02-01-02-16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      " -6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-02-02-01-16.wav\n",
      "03-01-05-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-02-02-02-16.wav\n",
      "03-01-05-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-01-01-01-16.wav\n",
      "03-01-06-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-01-01-02-16.wav\n",
      "03-01-06-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-01-02-01-16.wav\n",
      "03-01-06-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-01-02-02-16.wav\n",
      "03-01-06-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-02-01-01-16.wav\n",
      "03-01-06-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-02-01-02-16.wav\n",
      "03-01-06-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-02-02-01-16.wav\n",
      "03-01-06-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-02-02-02-16.wav\n",
      "03-01-06-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-01-01-01-16.wav\n",
      "03-01-07-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-01-01-02-16.wav\n",
      "03-01-07-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-01-02-01-16.wav\n",
      "03-01-07-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-01-02-02-16.wav\n",
      "03-01-07-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-02-01-01-16.wav\n",
      "03-01-07-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-02-01-02-16.wav\n",
      "03-01-07-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-02-02-01-16.wav\n",
      "03-01-07-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-02-02-02-16.wav\n",
      "03-01-07-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-01-01-01-16.wav\n",
      "03-01-08-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-01-01-02-16.wav\n",
      "03-01-08-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-01-02-01-16.wav\n",
      "03-01-08-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-01-02-02-16.wav\n",
      "03-01-08-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-02-01-01-16.wav\n",
      "03-01-08-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-02-01-02-16.wav\n",
      "03-01-08-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-02-02-01-16.wav\n",
      "03-01-08-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-02-02-02-16.wav\n",
      "03-01-08-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-01-01-01-01-17.wav\n",
      "03-01-01-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-01-01-01-02-17.wav\n",
      "03-01-01-01-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-04  3.3569336e-04  3.0517578e-04 ... -9.1552734e-05\n",
      " -9.1552734e-05 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[9.1552734e-05 9.1552734e-05 6.1035156e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ... -9.1552734e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -3.0517578e-05  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-01-01-02-01-17.wav\n",
      "03-01-01-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-01-01-02-02-17.wav\n",
      "03-01-01-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-01-01-01-17.wav\n",
      "03-01-02-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-01-01-02-17.wav\n",
      "03-01-02-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-01-02-01-17.wav\n",
      "03-01-02-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-01-02-02-17.wav\n",
      "03-01-02-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-02-01-01-17.wav\n",
      "03-01-02-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-02-01-02-17.wav\n",
      "03-01-02-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-02-02-01-17.wav\n",
      "03-01-02-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-02-02-02-17.wav\n",
      "03-01-02-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-01-01-01-17.wav\n",
      "03-01-03-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-01-01-02-17.wav\n",
      "03-01-03-01-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  6.1035156e-05  6.1035156e-05 ... -9.1552734e-05\n",
      " -9.1552734e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-2.1362305e-04 -9.1552734e-05  0.0000000e+00 ... -1.2207031e-04\n",
      " -1.5258789e-04 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 6.1035156e-05 9.1552734e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[1.8310547e-04 1.5258789e-04 3.0517578e-05 ... 9.1552734e-05 9.1552734e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-01-02-01-17.wav\n",
      "03-01-03-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-01-02-02-17.wav\n",
      "03-01-03-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-02-01-01-17.wav\n",
      "03-01-03-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-02-01-02-17.wav\n",
      "03-01-03-02-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 1.2207031e-04  1.2207031e-04  1.5258789e-04 ... -2.4414062e-04\n",
      " -9.1552734e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.3569336e-04 -9.1552734e-05  3.9672852e-04 ...  1.5258789e-04\n",
      "  1.2207031e-04  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 1.8310547e-04  1.8310547e-04  6.1035156e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-02-02-01-17.wav\n",
      "03-01-03-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-02-02-02-17.wav\n",
      "03-01-03-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-01-01-01-17.wav\n",
      "03-01-04-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-01-01-02-17.wav\n",
      "03-01-04-01-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 3.0517578e-05 ... 1.2207031e-04 1.5258789e-04\n",
      " 1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-0.00012207 -0.00015259 -0.00018311 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 9.1552734e-05 9.1552734e-05 ... 6.1035156e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00018311 0.00018311 0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-01-02-01-17.wav\n",
      "03-01-04-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-01-02-02-17.wav\n",
      "03-01-04-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-02-01-01-17.wav\n",
      "03-01-04-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-02-01-02-17.wav\n",
      "03-01-04-02-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[1.8310547e-04 1.2207031e-04 3.0517578e-05 ... 1.2207031e-04 1.2207031e-04\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ... -6.1035156e-05\n",
      " -6.1035156e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-04 -3.3569336e-04 -5.7983398e-04 ...  6.1035156e-05\n",
      "  9.1552734e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-02-02-01-17.wav\n",
      "03-01-04-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-02-02-02-17.wav\n",
      "03-01-04-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-01-01-01-17.wav\n",
      "03-01-05-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-01-01-02-17.wav\n",
      "03-01-05-01-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -6.1035156e-05 -6.1035156e-05 ... -1.5258789e-04\n",
      " -1.5258789e-04 -1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ... -1.2207031e-04\n",
      " -1.5258789e-04 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[1.2207031e-04 3.0517578e-05 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-01-02-01-17.wav\n",
      "03-01-05-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-01-02-02-17.wav\n",
      "03-01-05-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-02-01-01-17.wav\n",
      "03-01-05-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-02-01-02-17.wav\n",
      "03-01-05-02-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-1.5258789e-04 -6.1035156e-05 -1.5258789e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.00018311 0.00018311 0.00018311 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-2.4414062e-04 -9.1552734e-05 -3.0517578e-05 ... -6.1035156e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-02-02-01-17.wav\n",
      "03-01-05-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-02-02-02-17.wav\n",
      "03-01-05-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-01-01-01-17.wav\n",
      "03-01-06-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-01-01-02-17.wav\n",
      "03-01-06-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-01-02-01-17.wav\n",
      "03-01-06-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-01-02-02-17.wav\n",
      "03-01-06-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-02-01-01-17.wav\n",
      "03-01-06-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-02-01-02-17.wav\n",
      "03-01-06-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-02-02-01-17.wav\n",
      "03-01-06-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-02-02-02-17.wav\n",
      "03-01-06-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-01-01-01-17.wav\n",
      "03-01-07-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-01-01-02-17.wav\n",
      "03-01-07-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-01-02-01-17.wav\n",
      "03-01-07-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-01-02-02-17.wav\n",
      "03-01-07-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-02-01-01-17.wav\n",
      "03-01-07-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-02-01-02-17.wav\n",
      "03-01-07-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-02-02-01-17.wav\n",
      "03-01-07-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-02-02-02-17.wav\n",
      "03-01-07-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-01-01-01-17.wav\n",
      "03-01-08-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-01-01-02-17.wav\n",
      "03-01-08-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-01-02-01-17.wav\n",
      "03-01-08-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-01-02-02-17.wav\n",
      "03-01-08-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-02-01-01-17.wav\n",
      "03-01-08-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-02-01-02-17.wav\n",
      "03-01-08-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-02-02-01-17.wav\n",
      "03-01-08-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-02-02-02-17.wav\n",
      "03-01-08-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-01-01-01-01-18.wav\n",
      "03-01-01-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-01-01-01-02-18.wav\n",
      "03-01-01-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-01-01-02-01-18.wav\n",
      "03-01-01-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-01-01-02-02-18.wav\n",
      "03-01-01-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-01-01-01-18.wav\n",
      "03-01-02-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-01-01-02-18.wav\n",
      "03-01-02-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-01-02-01-18.wav\n",
      "03-01-02-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-01-02-02-18.wav\n",
      "03-01-02-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-02-01-01-18.wav\n",
      "03-01-02-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-02-01-02-18.wav\n",
      "03-01-02-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-02-02-01-18.wav\n",
      "03-01-02-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-02-02-02-18.wav\n",
      "03-01-02-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-01-01-01-18.wav\n",
      "03-01-03-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-01-01-02-18.wav\n",
      "03-01-03-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-01-02-01-18.wav\n",
      "03-01-03-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-01-02-02-18.wav\n",
      "03-01-03-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-02-01-01-18.wav\n",
      "03-01-03-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-02-01-02-18.wav\n",
      "03-01-03-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-02-02-01-18.wav\n",
      "03-01-03-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-02-02-02-18.wav\n",
      "03-01-03-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-01-01-01-18.wav\n",
      "03-01-04-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-01-01-02-18.wav\n",
      "03-01-04-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-01-02-01-18.wav\n",
      "03-01-04-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-01-02-02-18.wav\n",
      "03-01-04-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-02-01-01-18.wav\n",
      "03-01-04-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-02-01-02-18.wav\n",
      "03-01-04-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-02-02-01-18.wav\n",
      "03-01-04-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-02-02-02-18.wav\n",
      "03-01-04-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-01-01-01-18.wav\n",
      "03-01-05-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-01-01-02-18.wav\n",
      "03-01-05-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-01-02-01-18.wav\n",
      "03-01-05-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-01-02-02-18.wav\n",
      "03-01-05-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-02-01-01-18.wav\n",
      "03-01-05-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-02-01-02-18.wav\n",
      "03-01-05-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-02-02-01-18.wav\n",
      "03-01-05-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-02-02-02-18.wav\n",
      "03-01-05-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-01-01-01-18.wav\n",
      "03-01-06-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-01-01-02-18.wav\n",
      "03-01-06-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-01-02-01-18.wav\n",
      "03-01-06-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-01-02-02-18.wav\n",
      "03-01-06-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-02-01-01-18.wav\n",
      "03-01-06-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-02-01-02-18.wav\n",
      "03-01-06-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-02-02-01-18.wav\n",
      "03-01-06-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-02-02-02-18.wav\n",
      "03-01-06-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-01-01-01-18.wav\n",
      "03-01-07-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-01-01-02-18.wav\n",
      "03-01-07-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-01-02-01-18.wav\n",
      "03-01-07-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-01-02-02-18.wav\n",
      "03-01-07-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-02-01-01-18.wav\n",
      "03-01-07-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-02-01-02-18.wav\n",
      "03-01-07-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-02-02-01-18.wav\n",
      "03-01-07-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-02-02-02-18.wav\n",
      "03-01-07-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-01-01-01-18.wav\n",
      "03-01-08-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-01-01-02-18.wav\n",
      "03-01-08-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-01-02-01-18.wav\n",
      "03-01-08-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-01-02-02-18.wav\n",
      "03-01-08-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-02-01-01-18.wav\n",
      "03-01-08-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-02-01-02-18.wav\n",
      "03-01-08-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-02-02-01-18.wav\n",
      "03-01-08-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-02-02-02-18.wav\n",
      "03-01-08-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-01-01-01-01-19.wav\n",
      "03-01-01-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-01-01-01-02-19.wav\n",
      "03-01-01-01-01-02-19.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-01-01-02-01-19.wav\n",
      "03-01-01-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-01-01-02-02-19.wav\n",
      "03-01-01-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-01-01-01-19.wav\n",
      "03-01-02-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-01-01-02-19.wav\n",
      "03-01-02-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-01-02-01-19.wav\n",
      "03-01-02-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-01-02-02-19.wav\n",
      "03-01-02-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-02-01-01-19.wav\n",
      "03-01-02-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-02-01-02-19.wav\n",
      "03-01-02-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-02-02-01-19.wav\n",
      "03-01-02-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-02-02-02-19.wav\n",
      "03-01-02-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-01-01-01-19.wav\n",
      "03-01-03-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-01-01-02-19.wav\n",
      "03-01-03-01-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-0.00018311 -0.00018311 -0.00021362 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 1.2207031e-04  1.2207031e-04  1.2207031e-04 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00308228 0.00311279 0.00308228] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 3.0517578e-05 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-01-02-01-19.wav\n",
      "03-01-03-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-01-02-02-19.wav\n",
      "03-01-03-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-02-01-01-19.wav\n",
      "03-01-03-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-02-01-02-19.wav\n",
      "03-01-03-02-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 0.0000000e+00 ... 9.1552734e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -1.2207031e-04 -1.2207031e-04 ...  9.1552734e-05\n",
      "  9.1552734e-05  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.00036621  0.00045776  0.00048828 ... -0.00021362 -0.00021362\n",
      " -0.00021362] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-02-02-01-19.wav\n",
      "03-01-03-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-02-02-02-19.wav\n",
      "03-01-03-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-01-01-01-19.wav\n",
      "03-01-04-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-01-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.00067139  0.00076294  0.00106812 ...  0.00344849 -0.00195312\n",
      " -0.00204468] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -1.2207031e-04 -1.2207031e-04 ...  3.0517578e-05\n",
      "  3.0517578e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 6.1035156e-05 ... 6.1035156e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-04-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-01-02-01-19.wav\n",
      "03-01-04-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-01-02-02-19.wav\n",
      "03-01-04-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-02-01-01-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 1.2207031e-04  1.2207031e-04  1.2207031e-04 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00125122 -0.00125122\n",
      " -0.00125122] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-04-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-02-01-02-19.wav\n",
      "03-01-04-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-02-02-01-19.wav\n",
      "03-01-04-02-02-01-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-0.0022583  -0.00228882 -0.00234985 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-0.00048828 -0.00036621 -0.00027466 ... -0.00021362 -0.00021362\n",
      " -0.00021362] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-02-02-02-19.wav\n",
      "03-01-04-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-01-01-01-19.wav\n",
      "03-01-05-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-01-01-02-19.wav\n",
      "03-01-05-01-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -1.2207031e-04 -9.1552734e-05 ...  3.9672852e-04\n",
      "  3.9672852e-04  3.6621094e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-0.00283813 -0.00286865 -0.00286865 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-01-02-01-19.wav\n",
      "03-01-05-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-01-02-02-19.wav\n",
      "03-01-05-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-02-01-01-19.wav\n",
      "03-01-05-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-02-01-02-19.wav\n",
      "03-01-05-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-02-02-01-19.wav\n",
      "03-01-05-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-02-02-02-19.wav\n",
      "03-01-05-02-02-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -9.1552734e-05\n",
      " -9.1552734e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05 -3.0517578e-05  2.1362305e-04 ...  0.0000000e+00\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-01-01-01-19.wav\n",
      "03-01-06-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-01-01-02-19.wav\n",
      "03-01-06-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-01-02-01-19.wav\n",
      "03-01-06-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-01-02-02-19.wav\n",
      "03-01-06-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-02-01-01-19.wav\n",
      "03-01-06-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-02-01-02-19.wav\n",
      "03-01-06-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-02-02-01-19.wav\n",
      "03-01-06-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-02-02-02-19.wav\n",
      "03-01-06-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-01-01-01-19.wav\n",
      "03-01-07-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-01-01-02-19.wav\n",
      "03-01-07-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-01-02-01-19.wav\n",
      "03-01-07-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-01-02-02-19.wav\n",
      "03-01-07-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-02-01-01-19.wav\n",
      "03-01-07-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-02-01-02-19.wav\n",
      "03-01-07-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-02-02-01-19.wav\n",
      "03-01-07-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-02-02-02-19.wav\n",
      "03-01-07-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-01-01-01-19.wav\n",
      "03-01-08-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-01-01-02-19.wav\n",
      "03-01-08-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-01-02-01-19.wav\n",
      "03-01-08-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-01-02-02-19.wav\n",
      "03-01-08-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-02-01-01-19.wav\n",
      "03-01-08-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-02-01-02-19.wav\n",
      "03-01-08-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-02-02-01-19.wav\n",
      "03-01-08-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-02-02-02-19.wav\n",
      "03-01-08-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-01-01-01-01-20.wav\n",
      "03-01-01-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-01-01-01-02-20.wav\n",
      "03-01-01-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-01-01-02-01-20.wav\n",
      "03-01-01-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-01-01-02-02-20.wav\n",
      "03-01-01-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-01-01-01-20.wav\n",
      "03-01-02-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-01-01-02-20.wav\n",
      "03-01-02-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-01-02-01-20.wav\n",
      "03-01-02-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-01-02-02-20.wav\n",
      "03-01-02-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-02-01-01-20.wav\n",
      "03-01-02-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-02-01-02-20.wav\n",
      "03-01-02-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-02-02-01-20.wav\n",
      "03-01-02-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-02-02-02-20.wav\n",
      "03-01-02-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-01-01-01-20.wav\n",
      "03-01-03-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-01-01-02-20.wav\n",
      "03-01-03-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-01-02-01-20.wav\n",
      "03-01-03-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-01-02-02-20.wav\n",
      "03-01-03-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-02-01-01-20.wav\n",
      "03-01-03-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-02-01-02-20.wav\n",
      "03-01-03-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-02-02-01-20.wav\n",
      "03-01-03-02-02-01-20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "  3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-02-02-02-20.wav\n",
      "03-01-03-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-01-01-01-20.wav\n",
      "03-01-04-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-01-01-02-20.wav\n",
      "03-01-04-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-01-02-01-20.wav\n",
      "03-01-04-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-01-02-02-20.wav\n",
      "03-01-04-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-02-01-01-20.wav\n",
      "03-01-04-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-02-01-02-20.wav\n",
      "03-01-04-02-01-02-20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.01150513 -0.0135498\n",
      "  0.01361084] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-02-02-01-20.wav\n",
      "03-01-04-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-02-02-02-20.wav\n",
      "03-01-04-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-01-01-01-20.wav\n",
      "03-01-05-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-01-01-02-20.wav\n",
      "03-01-05-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-01-02-01-20.wav\n",
      "03-01-05-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-01-02-02-20.wav\n",
      "03-01-05-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-02-01-01-20.wav\n",
      "03-01-05-02-01-01-20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05 -9.1552734e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ...  3.0517578e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-02-01-02-20.wav\n",
      "03-01-05-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-02-02-01-20.wav\n",
      "03-01-05-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-02-02-02-20.wav\n",
      "03-01-05-02-02-02-20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00 -3.0517578e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-01-01-01-20.wav\n",
      "03-01-06-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-01-01-02-20.wav\n",
      "03-01-06-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-01-02-01-20.wav\n",
      "03-01-06-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-01-02-02-20.wav\n",
      "03-01-06-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-02-01-01-20.wav\n",
      "03-01-06-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-02-01-02-20.wav\n",
      "03-01-06-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-02-02-01-20.wav\n",
      "03-01-06-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-02-02-02-20.wav\n",
      "03-01-06-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-01-01-01-20.wav\n",
      "03-01-07-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-01-01-02-20.wav\n",
      "03-01-07-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-01-02-01-20.wav\n",
      "03-01-07-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-01-02-02-20.wav\n",
      "03-01-07-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-02-01-01-20.wav\n",
      "03-01-07-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-02-01-02-20.wav\n",
      "03-01-07-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-02-02-01-20.wav\n",
      "03-01-07-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-02-02-02-20.wav\n",
      "03-01-07-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-01-01-01-20.wav\n",
      "03-01-08-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-01-01-02-20.wav\n",
      "03-01-08-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-01-02-01-20.wav\n",
      "03-01-08-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-01-02-02-20.wav\n",
      "03-01-08-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-02-01-01-20.wav\n",
      "03-01-08-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-02-01-02-20.wav\n",
      "03-01-08-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-02-02-01-20.wav\n",
      "03-01-08-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-02-02-02-20.wav\n",
      "03-01-08-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-01-01-01-01-21.wav\n",
      "03-01-01-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-01-01-01-02-21.wav\n",
      "03-01-01-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-01-01-02-01-21.wav\n",
      "03-01-01-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-01-01-02-02-21.wav\n",
      "03-01-01-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-01-01-01-21.wav\n",
      "03-01-02-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-01-01-02-21.wav\n",
      "03-01-02-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-01-02-01-21.wav\n",
      "03-01-02-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-01-02-02-21.wav\n",
      "03-01-02-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-02-01-01-21.wav\n",
      "03-01-02-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-02-01-02-21.wav\n",
      "03-01-02-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-02-02-01-21.wav\n",
      "03-01-02-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-02-02-02-21.wav\n",
      "03-01-02-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-01-01-01-21.wav\n",
      "03-01-03-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-01-01-02-21.wav\n",
      "03-01-03-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-01-02-01-21.wav\n",
      "03-01-03-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-01-02-02-21.wav\n",
      "03-01-03-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-02-01-01-21.wav\n",
      "03-01-03-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-02-01-02-21.wav\n",
      "03-01-03-02-01-02-21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-02-02-01-21.wav\n",
      "03-01-03-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-02-02-02-21.wav\n",
      "03-01-03-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-01-01-01-21.wav\n",
      "03-01-04-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-01-01-02-21.wav\n",
      "03-01-04-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-01-02-01-21.wav\n",
      "03-01-04-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-01-02-02-21.wav\n",
      "03-01-04-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-02-01-01-21.wav\n",
      "03-01-04-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-02-01-02-21.wav\n",
      "03-01-04-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-02-02-01-21.wav\n",
      "03-01-04-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-02-02-02-21.wav\n",
      "03-01-04-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-01-01-01-21.wav\n",
      "03-01-05-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-01-01-02-21.wav\n",
      "03-01-05-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-01-02-01-21.wav\n",
      "03-01-05-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-01-02-02-21.wav\n",
      "03-01-05-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-02-01-01-21.wav\n",
      "03-01-05-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-02-01-02-21.wav\n",
      "03-01-05-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-02-02-01-21.wav\n",
      "03-01-05-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-02-02-02-21.wav\n",
      "03-01-05-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-01-01-01-21.wav\n",
      "03-01-06-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-01-01-02-21.wav\n",
      "03-01-06-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-01-02-01-21.wav\n",
      "03-01-06-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-01-02-02-21.wav\n",
      "03-01-06-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-02-01-01-21.wav\n",
      "03-01-06-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-02-01-02-21.wav\n",
      "03-01-06-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-02-02-01-21.wav\n",
      "03-01-06-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-02-02-02-21.wav\n",
      "03-01-06-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-01-01-01-21.wav\n",
      "03-01-07-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-01-01-02-21.wav\n",
      "03-01-07-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-01-02-01-21.wav\n",
      "03-01-07-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-01-02-02-21.wav\n",
      "03-01-07-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-02-01-01-21.wav\n",
      "03-01-07-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-02-01-02-21.wav\n",
      "03-01-07-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-02-02-01-21.wav\n",
      "03-01-07-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-02-02-02-21.wav\n",
      "03-01-07-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-01-01-01-21.wav\n",
      "03-01-08-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-01-01-02-21.wav\n",
      "03-01-08-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-01-02-01-21.wav\n",
      "03-01-08-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-01-02-02-21.wav\n",
      "03-01-08-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-02-01-01-21.wav\n",
      "03-01-08-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-02-01-02-21.wav\n",
      "03-01-08-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-02-02-01-21.wav\n",
      "03-01-08-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-02-02-02-21.wav\n",
      "03-01-08-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-01-01-01-01-22.wav\n",
      "03-01-01-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-01-01-01-02-22.wav\n",
      "03-01-01-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-01-01-02-01-22.wav\n",
      "03-01-01-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-01-01-02-02-22.wav\n",
      "03-01-01-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-01-01-01-22.wav\n",
      "03-01-02-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-01-01-02-22.wav\n",
      "03-01-02-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-01-02-01-22.wav\n",
      "03-01-02-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-01-02-02-22.wav\n",
      "03-01-02-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-02-01-01-22.wav\n",
      "03-01-02-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-02-01-02-22.wav\n",
      "03-01-02-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-02-02-01-22.wav\n",
      "03-01-02-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-02-02-02-22.wav\n",
      "03-01-02-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-01-01-01-22.wav\n",
      "03-01-03-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-01-01-02-22.wav\n",
      "03-01-03-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-01-02-01-22.wav\n",
      "03-01-03-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-01-02-02-22.wav\n",
      "03-01-03-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-02-01-01-22.wav\n",
      "03-01-03-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-02-01-02-22.wav\n",
      "03-01-03-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-02-02-01-22.wav\n",
      "03-01-03-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-02-02-02-22.wav\n",
      "03-01-03-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-01-01-01-22.wav\n",
      "03-01-04-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-01-01-02-22.wav\n",
      "03-01-04-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-01-02-01-22.wav\n",
      "03-01-04-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-01-02-02-22.wav\n",
      "03-01-04-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-02-01-01-22.wav\n",
      "03-01-04-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-02-01-02-22.wav\n",
      "03-01-04-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-02-02-01-22.wav\n",
      "03-01-04-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-02-02-02-22.wav\n",
      "03-01-04-02-02-02-22.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-01-01-01-22.wav\n",
      "03-01-05-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-01-01-02-22.wav\n",
      "03-01-05-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-01-02-01-22.wav\n",
      "03-01-05-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-01-02-02-22.wav\n",
      "03-01-05-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-02-01-01-22.wav\n",
      "03-01-05-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-02-01-02-22.wav\n",
      "03-01-05-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-02-02-01-22.wav\n",
      "03-01-05-02-02-01-22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -6.1035156e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-02-02-02-22.wav\n",
      "03-01-05-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-01-01-01-22.wav\n",
      "03-01-06-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-01-01-02-22.wav\n",
      "03-01-06-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-01-02-01-22.wav\n",
      "03-01-06-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-01-02-02-22.wav\n",
      "03-01-06-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-02-01-01-22.wav\n",
      "03-01-06-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-02-01-02-22.wav\n",
      "03-01-06-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-02-02-01-22.wav\n",
      "03-01-06-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-02-02-02-22.wav\n",
      "03-01-06-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-01-01-01-22.wav\n",
      "03-01-07-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-01-01-02-22.wav\n",
      "03-01-07-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-01-02-01-22.wav\n",
      "03-01-07-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-01-02-02-22.wav\n",
      "03-01-07-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-02-01-01-22.wav\n",
      "03-01-07-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-02-01-02-22.wav\n",
      "03-01-07-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-02-02-01-22.wav\n",
      "03-01-07-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-02-02-02-22.wav\n",
      "03-01-07-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-01-01-01-22.wav\n",
      "03-01-08-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-01-01-02-22.wav\n",
      "03-01-08-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-01-02-01-22.wav\n",
      "03-01-08-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-01-02-02-22.wav\n",
      "03-01-08-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-02-01-01-22.wav\n",
      "03-01-08-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-02-01-02-22.wav\n",
      "03-01-08-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-02-02-01-22.wav\n",
      "03-01-08-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-02-02-02-22.wav\n",
      "03-01-08-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-01-01-01-01-23.wav\n",
      "03-01-01-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-01-01-01-02-23.wav\n",
      "03-01-01-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-01-01-02-01-23.wav\n",
      "03-01-01-01-02-01-23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-01-01-02-02-23.wav\n",
      "03-01-01-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-01-01-01-23.wav\n",
      "03-01-02-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-01-01-02-23.wav\n",
      "03-01-02-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-01-02-01-23.wav\n",
      "03-01-02-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-01-02-02-23.wav\n",
      "03-01-02-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-02-01-01-23.wav\n",
      "03-01-02-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-02-01-02-23.wav\n",
      "03-01-02-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-02-02-01-23.wav\n",
      "03-01-02-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-02-02-02-23.wav\n",
      "03-01-02-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-01-01-01-23.wav\n",
      "03-01-03-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-01-01-02-23.wav\n",
      "03-01-03-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-01-02-01-23.wav\n",
      "03-01-03-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-01-02-02-23.wav\n",
      "03-01-03-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-02-01-01-23.wav\n",
      "03-01-03-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-02-01-02-23.wav\n",
      "03-01-03-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-02-02-01-23.wav\n",
      "03-01-03-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-02-02-02-23.wav\n",
      "03-01-03-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-01-01-01-23.wav\n",
      "03-01-04-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-01-01-02-23.wav\n",
      "03-01-04-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-01-02-01-23.wav\n",
      "03-01-04-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-01-02-02-23.wav\n",
      "03-01-04-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-02-01-01-23.wav\n",
      "03-01-04-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-02-01-02-23.wav\n",
      "03-01-04-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-02-02-01-23.wav\n",
      "03-01-04-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-02-02-02-23.wav\n",
      "03-01-04-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-01-01-01-23.wav\n",
      "03-01-05-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-01-01-02-23.wav\n",
      "03-01-05-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-01-02-01-23.wav\n",
      "03-01-05-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-01-02-02-23.wav\n",
      "03-01-05-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-02-01-01-23.wav\n",
      "03-01-05-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-02-01-02-23.wav\n",
      "03-01-05-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-02-02-01-23.wav\n",
      "03-01-05-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-02-02-02-23.wav\n",
      "03-01-05-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-01-01-01-23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-06-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-01-01-02-23.wav\n",
      "03-01-06-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-01-02-01-23.wav\n",
      "03-01-06-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-01-02-02-23.wav\n",
      "03-01-06-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-02-01-01-23.wav\n",
      "03-01-06-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-02-01-02-23.wav\n",
      "03-01-06-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-02-02-01-23.wav\n",
      "03-01-06-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-02-02-02-23.wav\n",
      "03-01-06-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-01-01-01-23.wav\n",
      "03-01-07-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-01-01-02-23.wav\n",
      "03-01-07-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-01-02-01-23.wav\n",
      "03-01-07-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-01-02-02-23.wav\n",
      "03-01-07-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-02-01-01-23.wav\n",
      "03-01-07-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-02-01-02-23.wav\n",
      "03-01-07-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-02-02-01-23.wav\n",
      "03-01-07-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-02-02-02-23.wav\n",
      "03-01-07-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-01-01-01-23.wav\n",
      "03-01-08-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-01-01-02-23.wav\n",
      "03-01-08-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-01-02-01-23.wav\n",
      "03-01-08-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-01-02-02-23.wav\n",
      "03-01-08-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-02-01-01-23.wav\n",
      "03-01-08-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-02-01-02-23.wav\n",
      "03-01-08-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-02-02-01-23.wav\n",
      "03-01-08-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-02-02-02-23.wav\n",
      "03-01-08-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-01-01-01-01-24.wav\n",
      "03-01-01-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-01-01-01-02-24.wav\n",
      "03-01-01-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-01-01-02-01-24.wav\n",
      "03-01-01-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-01-01-02-02-24.wav\n",
      "03-01-01-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-01-01-01-24.wav\n",
      "03-01-02-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-01-01-02-24.wav\n",
      "03-01-02-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-01-02-01-24.wav\n",
      "03-01-02-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-01-02-02-24.wav\n",
      "03-01-02-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-02-01-01-24.wav\n",
      "03-01-02-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-02-01-02-24.wav\n",
      "03-01-02-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-02-02-01-24.wav\n",
      "03-01-02-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-02-02-02-24.wav\n",
      "03-01-02-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-01-01-01-24.wav\n",
      "03-01-03-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-01-01-02-24.wav\n",
      "03-01-03-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-01-02-01-24.wav\n",
      "03-01-03-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-01-02-02-24.wav\n",
      "03-01-03-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-02-01-01-24.wav\n",
      "03-01-03-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-02-01-02-24.wav\n",
      "03-01-03-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-02-02-01-24.wav\n",
      "03-01-03-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-02-02-02-24.wav\n",
      "03-01-03-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-01-01-01-24.wav\n",
      "03-01-04-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-01-01-02-24.wav\n",
      "03-01-04-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-01-02-01-24.wav\n",
      "03-01-04-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-01-02-02-24.wav\n",
      "03-01-04-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-02-01-01-24.wav\n",
      "03-01-04-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-02-01-02-24.wav\n",
      "03-01-04-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-02-02-01-24.wav\n",
      "03-01-04-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-02-02-02-24.wav\n",
      "03-01-04-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-01-01-01-24.wav\n",
      "03-01-05-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-01-01-02-24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -1.5258789e-04\n",
      " -1.5258789e-04 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-05-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-01-02-01-24.wav\n",
      "03-01-05-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-01-02-02-24.wav\n",
      "03-01-05-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-02-01-01-24.wav\n",
      "03-01-05-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-02-01-02-24.wav\n",
      "03-01-05-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-02-02-01-24.wav\n",
      "03-01-05-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-02-02-02-24.wav\n",
      "03-01-05-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-01-01-01-24.wav\n",
      "03-01-06-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-01-01-02-24.wav\n",
      "03-01-06-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-01-02-01-24.wav\n",
      "03-01-06-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-01-02-02-24.wav\n",
      "03-01-06-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-02-01-01-24.wav\n",
      "03-01-06-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-02-01-02-24.wav\n",
      "03-01-06-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-02-02-01-24.wav\n",
      "03-01-06-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-02-02-02-24.wav\n",
      "03-01-06-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-01-01-01-24.wav\n",
      "03-01-07-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-01-01-02-24.wav\n",
      "03-01-07-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-01-02-01-24.wav\n",
      "03-01-07-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-01-02-02-24.wav\n",
      "03-01-07-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-02-01-01-24.wav\n",
      "03-01-07-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-02-01-02-24.wav\n",
      "03-01-07-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-02-02-01-24.wav\n",
      "03-01-07-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-02-02-02-24.wav\n",
      "03-01-07-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-01-01-01-24.wav\n",
      "03-01-08-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-01-01-02-24.wav\n",
      "03-01-08-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-01-02-01-24.wav\n",
      "03-01-08-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-01-02-02-24.wav\n",
      "03-01-08-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-02-01-01-24.wav\n",
      "03-01-08-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-02-01-02-24.wav\n",
      "03-01-08-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-02-02-01-24.wav\n",
      "03-01-08-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-02-02-02-24.wav\n",
      "03-01-08-02-02-02-24.wav\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GO3OzGWt22Sq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((537, 180, 1), (135, 180, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train= np.asarray(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape\n",
    "x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "x_testcnn = np.expand_dims(X_test, axis=2)\n",
    "x_traincnn.shape,x_testcnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HmqNzFs85Ck6",
    "outputId": "18ef3b9d-a617-4aa4-9667-b52712b79d3f"
   },
   "source": [
    "# Configuration 1 - CNN_Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jhBOW8Rk5VKt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 180, 128)          768       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 180, 128)          0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 180, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 22, 128)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 22, 128)           82048     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 22, 128)           0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 22, 128)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2816)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 22536     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 105,352\n",
      "Trainable params: 105,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',input_shape=(180,1)))        #1\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',))                           #2\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8))                                                 #3\n",
    "model.add(Activation('softmax'))\n",
    "optimizer=keras.optimizers.Adam(lr=0.001)\n",
    "model.summary()\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3bc97e0100a1a7a1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3bc97e0100a1a7a1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "import tensorflow\n",
    "%reload_ext tensorboard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback=tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "%tensorboard --logdir logs/fit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K6opFz235tL0",
    "outputId": "b509e32f-8d14-477c-d8a1-35e919a159d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 4s 67ms/step - loss: 4.1007 - accuracy: 0.3073 - val_loss: 1.9732 - val_accuracy: 0.4667\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 2.6557 - accuracy: 0.3408 - val_loss: 2.1168 - val_accuracy: 0.3481\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.6290 - accuracy: 0.4302 - val_loss: 1.1655 - val_accuracy: 0.4963\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.4329 - accuracy: 0.4246 - val_loss: 1.1259 - val_accuracy: 0.5185\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.2434 - accuracy: 0.4562 - val_loss: 1.0140 - val_accuracy: 0.5259\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.2074 - accuracy: 0.4842 - val_loss: 0.9723 - val_accuracy: 0.5704\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.0925 - accuracy: 0.4786 - val_loss: 0.8964 - val_accuracy: 0.5852\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.0246 - accuracy: 0.5251 - val_loss: 0.9447 - val_accuracy: 0.5481\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.9788 - accuracy: 0.5345 - val_loss: 0.9268 - val_accuracy: 0.5778\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.9382 - accuracy: 0.5512 - val_loss: 0.9134 - val_accuracy: 0.5778\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.9760 - accuracy: 0.5419 - val_loss: 0.8900 - val_accuracy: 0.4889\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.0182 - accuracy: 0.5214 - val_loss: 0.9507 - val_accuracy: 0.5556\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.9416 - accuracy: 0.5903 - val_loss: 0.9847 - val_accuracy: 0.5630\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.9360 - accuracy: 0.5717 - val_loss: 0.9256 - val_accuracy: 0.5037\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.8657 - accuracy: 0.6071 - val_loss: 0.8282 - val_accuracy: 0.5704\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.8792 - accuracy: 0.6034 - val_loss: 0.8481 - val_accuracy: 0.5407\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.8324 - accuracy: 0.6127 - val_loss: 0.8203 - val_accuracy: 0.6000\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.8378 - accuracy: 0.6294 - val_loss: 0.8592 - val_accuracy: 0.5852\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.8038 - accuracy: 0.6425 - val_loss: 0.8196 - val_accuracy: 0.5630\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.7928 - accuracy: 0.6667 - val_loss: 0.9200 - val_accuracy: 0.6074\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 0.8048 - accuracy: 0.6462 - val_loss: 0.8801 - val_accuracy: 0.6148\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.8098 - accuracy: 0.6406 - val_loss: 0.8598 - val_accuracy: 0.5852\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.7649 - accuracy: 0.6574 - val_loss: 0.8037 - val_accuracy: 0.5926\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.7580 - accuracy: 0.6760 - val_loss: 0.9309 - val_accuracy: 0.6148\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.7183 - accuracy: 0.7114 - val_loss: 0.7166 - val_accuracy: 0.6444\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.7375 - accuracy: 0.7058 - val_loss: 0.7392 - val_accuracy: 0.6222\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.6899 - accuracy: 0.7356 - val_loss: 0.8380 - val_accuracy: 0.6444\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.6552 - accuracy: 0.7337 - val_loss: 0.7581 - val_accuracy: 0.5926\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.6845 - accuracy: 0.7169 - val_loss: 0.8047 - val_accuracy: 0.6593\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.6711 - accuracy: 0.7039 - val_loss: 0.7052 - val_accuracy: 0.6222\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.6704 - accuracy: 0.7449 - val_loss: 0.7374 - val_accuracy: 0.6667\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.6547 - accuracy: 0.7412 - val_loss: 0.6896 - val_accuracy: 0.6667\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6250 - accuracy: 0.7393 - val_loss: 0.6612 - val_accuracy: 0.7037\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 0.5853 - accuracy: 0.7728 - val_loss: 0.7428 - val_accuracy: 0.6222\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.5848 - accuracy: 0.7542 - val_loss: 0.7095 - val_accuracy: 0.6593\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.5632 - accuracy: 0.7709 - val_loss: 0.7369 - val_accuracy: 0.6593\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.5895 - accuracy: 0.7654 - val_loss: 0.6951 - val_accuracy: 0.6815\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 0.5385 - accuracy: 0.7858 - val_loss: 0.6554 - val_accuracy: 0.6815\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.4932 - accuracy: 0.8287 - val_loss: 0.7119 - val_accuracy: 0.6667\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 0.5119 - accuracy: 0.7858 - val_loss: 0.7493 - val_accuracy: 0.6296\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.5499 - accuracy: 0.7970 - val_loss: 1.5742 - val_accuracy: 0.6593\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.6416 - accuracy: 0.7914 - val_loss: 0.7018 - val_accuracy: 0.6815\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.5789 - accuracy: 0.7914 - val_loss: 0.6976 - val_accuracy: 0.6519\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 0.5187 - accuracy: 0.7896 - val_loss: 0.6733 - val_accuracy: 0.6815\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.4898 - accuracy: 0.8138 - val_loss: 0.7106 - val_accuracy: 0.6444\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.4755 - accuracy: 0.8268 - val_loss: 0.7006 - val_accuracy: 0.6963\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 0.4501 - accuracy: 0.8305 - val_loss: 0.6867 - val_accuracy: 0.6519\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.4561 - accuracy: 0.8007 - val_loss: 0.7366 - val_accuracy: 0.6741\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 0.4767 - accuracy: 0.8101 - val_loss: 0.7021 - val_accuracy: 0.7037\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 0.4085 - accuracy: 0.8603 - val_loss: 0.7738 - val_accuracy: 0.6889\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=20, epochs=50, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRBYh-bMHucX"
   },
   "outputs": [],
   "source": [
    "em=['happy','sad','neutral','angry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using Config-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "GrrqoLzFAJDq",
    "outputId": "127a4973-55a9-4310-9df2-5d2ccef3f574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step\n",
      "sad\n",
      "[5.91337346e-02 1.51712456e-07 1.99179841e-21 3.66753484e-05\n",
      " 9.40829515e-01 9.27262681e-21 1.01231055e-19 1.24379479e-21]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_testcnn)\n",
    "n=predictions[1]\n",
    "print(em[1])\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "CxJc4kIaD9IK",
    "outputId": "943689bb-a472-4a03-fd96-38a5d9e4c69e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7738 - accuracy: 0.6889\n",
      "Restored model, accuracy: 68.89%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kVanJ86-FhwS",
    "outputId": "c8194727-9ef5-4e72-d1e2-26c6100cdb74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "result : happy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16348\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    }
   ],
   "source": [
    "filename = \"C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset/Actor_02/03-01-01-01-02-01-02.wav\"\n",
    "features = np.array(extract_feature(filename, mfcc=True, chroma=True, mel=True).reshape(1, -1))\n",
    "f=np.expand_dims(features,axis=2)\n",
    "result = model.predict(f)[0]\n",
    "print(\"result :\",em[int(result[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K1vlkqDPlA8A"
   },
   "source": [
    "# Configuration 2 - CNN_RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQR38pmCSaNU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 180, 128)          768       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 180, 128)          0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 180, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 22, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 22, 128)           82048     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 22, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 2, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, 128)            0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 2, 128)            82048     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 2, 128)            0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 2, 128)            0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 2056      \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166,920\n",
      "Trainable params: 166,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "um = Sequential()\n",
    "\n",
    "um.add(Conv1D(128, 5,padding='same',input_shape=(180,1)))#1\n",
    "um.add(Activation('relu'))\n",
    "um.add(Dropout(0.25))\n",
    "um.add(MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "um.add(Conv1D(128, 5,padding='same',))                  #2\n",
    "um.add(Activation('relu'))\n",
    "um.add(MaxPooling1D(pool_size=(8)))\n",
    "um.add(Dropout(0.25))\n",
    "\n",
    "um.add(Conv1D(128, 5,padding='same',))                  #3\n",
    "um.add(Activation('relu'))\n",
    "um.add(Dropout(0.25))\n",
    "\n",
    "um.add(Flatten())\n",
    "um.add(Dense(8))                                        #4                      \n",
    "um.add(Activation('softmax'))\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.00005,epsilon=None,rho=0.9,decay=0.0)\n",
    "\n",
    "um.summary()\n",
    "\n",
    "um.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0XiAWqd1bg5M",
    "outputId": "7c46bbcc-c4b1-425d-f06d-5f516ac6a531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 4s 58ms/step - loss: 13.4428 - accuracy: 0.1210 - val_loss: 2.3872 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 7.6372 - accuracy: 0.2421 - val_loss: 2.6835 - val_accuracy: 0.3630\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 6.6623 - accuracy: 0.2737 - val_loss: 2.2811 - val_accuracy: 0.3704\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 6.0542 - accuracy: 0.2905 - val_loss: 2.1519 - val_accuracy: 0.4000\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 5.2948 - accuracy: 0.3333 - val_loss: 2.4952 - val_accuracy: 0.4000\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 5.4085 - accuracy: 0.2868 - val_loss: 1.7126 - val_accuracy: 0.4296\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 4.9976 - accuracy: 0.2644 - val_loss: 1.6750 - val_accuracy: 0.4370\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 4.3886 - accuracy: 0.2905 - val_loss: 1.6748 - val_accuracy: 0.4370\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 3.5629 - accuracy: 0.3277 - val_loss: 1.5749 - val_accuracy: 0.4519\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 3.7594 - accuracy: 0.3054 - val_loss: 1.5375 - val_accuracy: 0.4444\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 3.3740 - accuracy: 0.3352 - val_loss: 1.6275 - val_accuracy: 0.4296\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 3.1349 - accuracy: 0.3128 - val_loss: 1.4953 - val_accuracy: 0.4519\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 3.0104 - accuracy: 0.3371 - val_loss: 1.5787 - val_accuracy: 0.4444\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 2.8449 - accuracy: 0.2998 - val_loss: 1.3847 - val_accuracy: 0.4519\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 2.5873 - accuracy: 0.3408 - val_loss: 1.3453 - val_accuracy: 0.4444\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 2.4354 - accuracy: 0.3240 - val_loss: 1.2269 - val_accuracy: 0.4667\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 2.2866 - accuracy: 0.3501 - val_loss: 1.2343 - val_accuracy: 0.4741\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 2.4238 - accuracy: 0.3091 - val_loss: 1.2192 - val_accuracy: 0.4741\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 2.2767 - accuracy: 0.3203 - val_loss: 1.1934 - val_accuracy: 0.4667\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 2.1795 - accuracy: 0.3426 - val_loss: 1.2204 - val_accuracy: 0.4667\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 2.0630 - accuracy: 0.3184 - val_loss: 1.2307 - val_accuracy: 0.4889\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.9347 - accuracy: 0.3315 - val_loss: 1.1979 - val_accuracy: 0.4963\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.9641 - accuracy: 0.3371 - val_loss: 1.2306 - val_accuracy: 0.4741\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.8121 - accuracy: 0.3669 - val_loss: 1.2208 - val_accuracy: 0.4593\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.8235 - accuracy: 0.3333 - val_loss: 1.2393 - val_accuracy: 0.4074\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 1.7563 - accuracy: 0.3762 - val_loss: 1.2672 - val_accuracy: 0.4667\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.8069 - accuracy: 0.3389 - val_loss: 1.2682 - val_accuracy: 0.4370\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.7256 - accuracy: 0.3631 - val_loss: 1.2783 - val_accuracy: 0.4667\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.6789 - accuracy: 0.3724 - val_loss: 1.2837 - val_accuracy: 0.4148\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.6690 - accuracy: 0.3240 - val_loss: 1.2948 - val_accuracy: 0.4148\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.5791 - accuracy: 0.3706 - val_loss: 1.3267 - val_accuracy: 0.3778\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.5606 - accuracy: 0.3873 - val_loss: 1.3017 - val_accuracy: 0.4296\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.5418 - accuracy: 0.3724 - val_loss: 1.3382 - val_accuracy: 0.4148\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.5366 - accuracy: 0.4004 - val_loss: 1.3153 - val_accuracy: 0.3926\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.6096 - accuracy: 0.3389 - val_loss: 1.2752 - val_accuracy: 0.5185\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.5037 - accuracy: 0.3687 - val_loss: 1.2438 - val_accuracy: 0.5111\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.5337 - accuracy: 0.3669 - val_loss: 1.2114 - val_accuracy: 0.5037\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.5166 - accuracy: 0.3613 - val_loss: 1.2397 - val_accuracy: 0.4370\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.5437 - accuracy: 0.3724 - val_loss: 1.2546 - val_accuracy: 0.4519\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.4441 - accuracy: 0.3836 - val_loss: 1.2865 - val_accuracy: 0.4074\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.4241 - accuracy: 0.3948 - val_loss: 1.2656 - val_accuracy: 0.4370\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.4120 - accuracy: 0.3892 - val_loss: 1.2140 - val_accuracy: 0.5259\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.4016 - accuracy: 0.3929 - val_loss: 1.2148 - val_accuracy: 0.4741\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.3887 - accuracy: 0.4078 - val_loss: 1.2353 - val_accuracy: 0.4519\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.3843 - accuracy: 0.4041 - val_loss: 1.2257 - val_accuracy: 0.4074\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.4279 - accuracy: 0.3818 - val_loss: 1.2242 - val_accuracy: 0.4074\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.4123 - accuracy: 0.3855 - val_loss: 1.2280 - val_accuracy: 0.3778\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.4088 - accuracy: 0.3706 - val_loss: 1.2137 - val_accuracy: 0.4370\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.4088 - accuracy: 0.3948 - val_loss: 1.2120 - val_accuracy: 0.4889\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.3916 - accuracy: 0.4041 - val_loss: 1.2153 - val_accuracy: 0.5037\n"
     ]
    }
   ],
   "source": [
    "umhistory=um.fit(x_traincnn, y_train, batch_size=20, epochs=50, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 16380), started 0:01:37 ago. (Use '!kill 16380' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a3650ca249e71e90\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a3650ca249e71e90\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback=tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using Config - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yUtQ8Bwjhcmw",
    "outputId": "e2fb5814-290f-47fe-b4e3-7dbaec5c432d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/step - loss: 1.2153 - accuracy: 0.5037\n",
      "Restored model, accuracy: 50.37%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = um.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Abdy_mt4nABa"
   },
   "source": [
    "# Configuration 2 - CNN2_Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V43ptFvXm-bj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_5 (Conv1D)           (None, 180, 128)          768       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 180, 128)          0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 180, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 22, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 22, 128)           82048     \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 22, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 2, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 2, 128)            0         \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 2, 128)            82048     \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 2, 128)            0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 2, 128)            0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 2, 128)            82048     \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 2, 128)            0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 2, 128)            0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 2056      \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 248,968\n",
      "Trainable params: 248,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "sm = Sequential()\n",
    "\n",
    "sm.add(Conv1D(128, 5,padding='same',input_shape=(180,1)))#1\n",
    "sm.add(Activation('relu'))\n",
    "sm.add(Dropout(0.1))\n",
    "sm.add(MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "sm.add(Conv1D(128, 5,padding='same',))                  #2\n",
    "sm.add(Activation('relu'))\n",
    "sm.add(MaxPooling1D(pool_size=(8)))\n",
    "sm.add(Dropout(0.1))\n",
    "\n",
    "sm.add(Conv1D(128, 5,padding='same',))                  #3\n",
    "sm.add(Activation('relu'))\n",
    "sm.add(Dropout(0.1))\n",
    "\n",
    "sm.add(Conv1D(128, 5,padding='same',))                  #4\n",
    "sm.add(Activation('relu'))\n",
    "sm.add(Dropout(0.1))\n",
    "\n",
    "sm.add(Flatten())\n",
    "sm.add(Dense(8))                                        #5                     \n",
    "sm.add(Activation('softmax'))\n",
    "\n",
    "sm.summary()\n",
    "sm.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 4s 51ms/step - loss: 2.7081 - accuracy: 0.2812 - val_loss: 1.3347 - val_accuracy: 0.4370\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.4238 - accuracy: 0.3333 - val_loss: 1.2959 - val_accuracy: 0.3556\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.3077 - accuracy: 0.3911 - val_loss: 1.3061 - val_accuracy: 0.4296\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.3154 - accuracy: 0.3892 - val_loss: 1.1946 - val_accuracy: 0.4074\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 1.2312 - accuracy: 0.4339 - val_loss: 1.1054 - val_accuracy: 0.5333\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.2415 - accuracy: 0.4227 - val_loss: 1.1284 - val_accuracy: 0.5481\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.2345 - accuracy: 0.4264 - val_loss: 1.1508 - val_accuracy: 0.4074\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.2567 - accuracy: 0.4134 - val_loss: 1.0740 - val_accuracy: 0.5259\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.1596 - accuracy: 0.4655 - val_loss: 1.0313 - val_accuracy: 0.5037\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.1787 - accuracy: 0.4525 - val_loss: 1.0720 - val_accuracy: 0.4148\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 1.1480 - accuracy: 0.4562 - val_loss: 0.9631 - val_accuracy: 0.5481\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.1086 - accuracy: 0.4730 - val_loss: 1.0031 - val_accuracy: 0.5407\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.1122 - accuracy: 0.4693 - val_loss: 1.2858 - val_accuracy: 0.3704\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.1054 - accuracy: 0.4749 - val_loss: 1.0171 - val_accuracy: 0.4593\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.0637 - accuracy: 0.4972 - val_loss: 1.0215 - val_accuracy: 0.5926\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.1214 - accuracy: 0.4507 - val_loss: 0.9695 - val_accuracy: 0.5333\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.0271 - accuracy: 0.5493 - val_loss: 0.9662 - val_accuracy: 0.5037\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.9861 - accuracy: 0.5363 - val_loss: 0.9443 - val_accuracy: 0.5926\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.9833 - accuracy: 0.5382 - val_loss: 0.9365 - val_accuracy: 0.5037\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.9913 - accuracy: 0.5177 - val_loss: 0.9564 - val_accuracy: 0.5556\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.0063 - accuracy: 0.5102 - val_loss: 1.0562 - val_accuracy: 0.5481\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.0239 - accuracy: 0.5289 - val_loss: 0.9691 - val_accuracy: 0.5185\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.9793 - accuracy: 0.4935 - val_loss: 0.9366 - val_accuracy: 0.6296\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.9980 - accuracy: 0.5419 - val_loss: 0.9167 - val_accuracy: 0.5704\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.9574 - accuracy: 0.5475 - val_loss: 0.9649 - val_accuracy: 0.6000\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.9590 - accuracy: 0.5475 - val_loss: 0.8277 - val_accuracy: 0.6444\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.9306 - accuracy: 0.5587 - val_loss: 0.8324 - val_accuracy: 0.6148\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.9270 - accuracy: 0.5736 - val_loss: 0.9005 - val_accuracy: 0.6370\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.9614 - accuracy: 0.5661 - val_loss: 0.8596 - val_accuracy: 0.5852\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.9176 - accuracy: 0.5624 - val_loss: 0.8006 - val_accuracy: 0.6074\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.9071 - accuracy: 0.5791 - val_loss: 0.8059 - val_accuracy: 0.6444\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.9039 - accuracy: 0.5791 - val_loss: 1.0016 - val_accuracy: 0.6741\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.9166 - accuracy: 0.5791 - val_loss: 0.8316 - val_accuracy: 0.6370\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.9075 - accuracy: 0.5736 - val_loss: 0.8728 - val_accuracy: 0.5704\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.8795 - accuracy: 0.5940 - val_loss: 0.8249 - val_accuracy: 0.6519\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.9044 - accuracy: 0.6108 - val_loss: 0.8624 - val_accuracy: 0.5481\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.8622 - accuracy: 0.6108 - val_loss: 0.8984 - val_accuracy: 0.6370\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.9042 - accuracy: 0.5605 - val_loss: 0.7962 - val_accuracy: 0.6519\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.8587 - accuracy: 0.6127 - val_loss: 0.8064 - val_accuracy: 0.5704\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.8935 - accuracy: 0.5810 - val_loss: 0.8934 - val_accuracy: 0.5407\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.8285 - accuracy: 0.6294 - val_loss: 0.7993 - val_accuracy: 0.6222\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.8679 - accuracy: 0.5754 - val_loss: 0.8346 - val_accuracy: 0.6370\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 0.8204 - accuracy: 0.6071 - val_loss: 0.8400 - val_accuracy: 0.6296\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.8096 - accuracy: 0.6592 - val_loss: 0.7284 - val_accuracy: 0.6593\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.7794 - accuracy: 0.6480 - val_loss: 0.8128 - val_accuracy: 0.6000\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.7948 - accuracy: 0.6574 - val_loss: 0.8088 - val_accuracy: 0.6444\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.8058 - accuracy: 0.6201 - val_loss: 0.8317 - val_accuracy: 0.6296\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.8157 - accuracy: 0.6089 - val_loss: 0.8334 - val_accuracy: 0.6222\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.7706 - accuracy: 0.6536 - val_loss: 0.9184 - val_accuracy: 0.5926\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.7852 - accuracy: 0.6611 - val_loss: 0.7018 - val_accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "smhistory=sm.fit(x_traincnn, y_train, batch_size=20, epochs=50, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K51eTwPjnIGJ",
    "outputId": "82569664-abb9-4322-8290-f724a128949b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 16380), started 0:02:25 ago. (Use '!kill 16380' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b1e99fc5a1add763\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b1e99fc5a1add763\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback=tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using Config - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LBS8v4sWnIjJ",
    "outputId": "34487bd9-7587-4805-a2e6-9f19e8e9e419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7018 - accuracy: 0.6667\n",
      "Restored model, accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = sm.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration 4 - LSTM_RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 180, 64)           16896     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,440\n",
      "Trainable params: 50,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_LSTM=Sequential()\n",
    "model_LSTM.add(layers.LSTM(64,return_sequences=True,input_shape=(180,1)))\n",
    "model_LSTM.add(layers.LSTM(64))\n",
    "model_LSTM.add(layers.Dense(8,activation='softmax'))\n",
    "print(model_LSTM.summary())\n",
    "model_LSTM.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 19s 261ms/step - loss: 1.4973 - accuracy: 0.2607 - val_loss: 1.4294 - val_accuracy: 0.2296\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 5s 179ms/step - loss: 1.3785 - accuracy: 0.2756 - val_loss: 1.3444 - val_accuracy: 0.3407\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 5s 189ms/step - loss: 1.3631 - accuracy: 0.3203 - val_loss: 1.3756 - val_accuracy: 0.3037\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 5s 188ms/step - loss: 1.3718 - accuracy: 0.2756 - val_loss: 1.3530 - val_accuracy: 0.2296\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 6s 210ms/step - loss: 1.3716 - accuracy: 0.2551 - val_loss: 1.3598 - val_accuracy: 0.2296\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 1.3658 - accuracy: 0.2793 - val_loss: 1.3658 - val_accuracy: 0.2296\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.3659 - accuracy: 0.2849 - val_loss: 1.3781 - val_accuracy: 0.2296\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 1.3650 - accuracy: 0.2644 - val_loss: 1.3491 - val_accuracy: 0.2296\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 5s 176ms/step - loss: 1.3675 - accuracy: 0.2663 - val_loss: 1.3497 - val_accuracy: 0.2296\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.3661 - accuracy: 0.2719 - val_loss: 1.3423 - val_accuracy: 0.2296\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 5s 179ms/step - loss: 1.3705 - accuracy: 0.3259 - val_loss: 1.2320 - val_accuracy: 0.3481\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 5s 177ms/step - loss: 1.2883 - accuracy: 0.3799 - val_loss: 1.1738 - val_accuracy: 0.5259\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 5s 181ms/step - loss: 1.2879 - accuracy: 0.4171 - val_loss: 1.1714 - val_accuracy: 0.5111\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 1.2174 - accuracy: 0.4283 - val_loss: 1.3406 - val_accuracy: 0.3556\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 1.2106 - accuracy: 0.4376 - val_loss: 1.0667 - val_accuracy: 0.5481\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 5s 178ms/step - loss: 1.2033 - accuracy: 0.4320 - val_loss: 1.0930 - val_accuracy: 0.5630\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 5s 195ms/step - loss: 1.2038 - accuracy: 0.4562 - val_loss: 1.0744 - val_accuracy: 0.5630\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 1.1749 - accuracy: 0.4749 - val_loss: 1.0416 - val_accuracy: 0.5407\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 1.1584 - accuracy: 0.4693 - val_loss: 1.0373 - val_accuracy: 0.5037\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.1559 - accuracy: 0.4879 - val_loss: 0.9995 - val_accuracy: 0.5556\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 5s 177ms/step - loss: 1.1194 - accuracy: 0.4916 - val_loss: 1.0949 - val_accuracy: 0.5481\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 5s 192ms/step - loss: 1.1237 - accuracy: 0.4711 - val_loss: 1.3053 - val_accuracy: 0.4593\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 1.1088 - accuracy: 0.4711 - val_loss: 1.0377 - val_accuracy: 0.5185\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 6s 215ms/step - loss: 1.1013 - accuracy: 0.4879 - val_loss: 0.9544 - val_accuracy: 0.5407\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 5s 201ms/step - loss: 1.0973 - accuracy: 0.4804 - val_loss: 1.0177 - val_accuracy: 0.5630\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 5s 199ms/step - loss: 1.0784 - accuracy: 0.4804 - val_loss: 1.0718 - val_accuracy: 0.5704\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 5s 188ms/step - loss: 1.1184 - accuracy: 0.4935 - val_loss: 1.0341 - val_accuracy: 0.5037\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 5s 190ms/step - loss: 1.0668 - accuracy: 0.5047 - val_loss: 0.9578 - val_accuracy: 0.5333\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 5s 185ms/step - loss: 1.0726 - accuracy: 0.4916 - val_loss: 0.9389 - val_accuracy: 0.5407\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 1.0731 - accuracy: 0.4823 - val_loss: 0.9361 - val_accuracy: 0.5259\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 5s 184ms/step - loss: 1.0776 - accuracy: 0.5028 - val_loss: 0.9680 - val_accuracy: 0.5259\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 5s 189ms/step - loss: 1.0620 - accuracy: 0.5140 - val_loss: 0.9508 - val_accuracy: 0.5481\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 5s 186ms/step - loss: 1.0645 - accuracy: 0.5028 - val_loss: 1.0111 - val_accuracy: 0.5037\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 5s 184ms/step - loss: 1.0770 - accuracy: 0.5065 - val_loss: 1.0540 - val_accuracy: 0.4593\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 5s 181ms/step - loss: 1.0630 - accuracy: 0.5028 - val_loss: 0.9633 - val_accuracy: 0.5333\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 5s 180ms/step - loss: 1.0451 - accuracy: 0.4898 - val_loss: 0.9411 - val_accuracy: 0.5259\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 5s 195ms/step - loss: 1.0690 - accuracy: 0.5084 - val_loss: 0.9546 - val_accuracy: 0.5556\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 5s 179ms/step - loss: 1.0740 - accuracy: 0.4972 - val_loss: 0.9320 - val_accuracy: 0.5556\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.0594 - accuracy: 0.5289 - val_loss: 1.0081 - val_accuracy: 0.5185\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 6s 203ms/step - loss: 1.0772 - accuracy: 0.4823 - val_loss: 0.9527 - val_accuracy: 0.5481\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 1.0625 - accuracy: 0.5158 - val_loss: 0.9702 - val_accuracy: 0.5185\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 5s 191ms/step - loss: 1.0459 - accuracy: 0.5270 - val_loss: 0.9477 - val_accuracy: 0.5481\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 5s 176ms/step - loss: 1.0526 - accuracy: 0.5009 - val_loss: 0.9993 - val_accuracy: 0.5185\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 5s 182ms/step - loss: 1.0576 - accuracy: 0.5177 - val_loss: 0.9266 - val_accuracy: 0.5481\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 5s 176ms/step - loss: 1.0715 - accuracy: 0.5102 - val_loss: 0.9480 - val_accuracy: 0.5481\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 5s 189ms/step - loss: 1.0812 - accuracy: 0.5121 - val_loss: 0.9551 - val_accuracy: 0.5407\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.1230 - accuracy: 0.4842 - val_loss: 1.0343 - val_accuracy: 0.5778\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 6s 203ms/step - loss: 1.1071 - accuracy: 0.4953 - val_loss: 0.9557 - val_accuracy: 0.5556\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.0672 - accuracy: 0.5047 - val_loss: 0.9853 - val_accuracy: 0.5556\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 1.0604 - accuracy: 0.5233 - val_loss: 0.9576 - val_accuracy: 0.5407\n"
     ]
    }
   ],
   "source": [
    "umhistory=model_LSTM.fit(x_traincnn, y_train, batch_size=20, epochs=50, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Config - 4 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 72ms/step - loss: 0.9576 - accuracy: 0.5407\n",
      "Restored model, accuracy: 54.07%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model_LSTM.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Analysis and Visualization of all Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 16380), started 0:06:48 ago. (Use '!kill 16380' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9dc57b890dce85bd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9dc57b890dce85bd\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback=tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOQfsKtSS2nu7fsGE+IWtmN",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CNN_SpeechEmotion.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
